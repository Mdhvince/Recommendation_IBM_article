{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Cleaning steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/medhyvinceslas/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/medhyvinceslas/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/medhyvinceslas/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import recommender as r\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# NLP\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('user-item-interactions.csv')\n",
    "df_content = pd.read_csv('articles_community.csv')\n",
    "del df['Unnamed: 0']\n",
    "del df_content['Unnamed: 0']\n",
    "\n",
    "# make sure all articles from df are in df_content\n",
    "df = pd.merge(df, df_content[['article_id']], on='article_id', how='inner')\n",
    "\n",
    "df_content = df_content.drop(labels='doc_status', axis=1)\n",
    "df_content = df_content.drop_duplicates()\n",
    "\n",
    "#df = df.replace('no_email', np.nan)\n",
    "\n",
    "def email_mapper():\n",
    "    coded_dict = dict()\n",
    "    cter = 1\n",
    "    email_encoded = []\n",
    "    \n",
    "    for val in df['email']:\n",
    "        if val not in coded_dict:\n",
    "            coded_dict[val] = cter\n",
    "            cter+=1\n",
    "        \n",
    "        email_encoded.append(coded_dict[val])\n",
    "    return email_encoded\n",
    "\n",
    "email_encoded = email_mapper()\n",
    "del df['email']\n",
    "df['user_id'] = email_encoded\n",
    "\n",
    "# Rename my article name field to be the same in both dfs\n",
    "df_content['title'] = df_content['doc_full_name']\n",
    "df_content = df_content.drop(labels='doc_full_name', axis=1)\n",
    "\n",
    "df.article_id = df.article_id.astype('int64')\n",
    "df_content.article_id = df_content.article_id.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  user_id\n",
       "0         593  upload files to ibm data science experience us...        1\n",
       "1         593  upload files to ibm data science experience us...        2\n",
       "2         593  upload files to ibm data science experience us...        3\n",
       "3         593  upload files to ibm data science experience us...        4\n",
       "4         593  upload files to ibm data science experience us...        3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>Detect bad readings in real time using Python ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Detect Malfunctioning IoT Sensors with Streami...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...</td>\n",
       "      <td>See the forest, see the trees. Here lies the c...</td>\n",
       "      <td>1</td>\n",
       "      <td>Communicating data science: A guide to present...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...</td>\n",
       "      <td>Here’s this week’s news in Data Science and Bi...</td>\n",
       "      <td>2</td>\n",
       "      <td>This Week in Data Science (April 18, 2017)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...</td>\n",
       "      <td>Learn how distributed DBs solve the problem of...</td>\n",
       "      <td>3</td>\n",
       "      <td>DataLayer Conference: Boost the performance of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>This video demonstrates the power of IBM DataS...</td>\n",
       "      <td>4</td>\n",
       "      <td>Analyze NY Restaurant data using Spark in DSX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            doc_body  \\\n",
       "0  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "1  No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...   \n",
       "2  ☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...   \n",
       "3  DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...   \n",
       "4  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "\n",
       "                                     doc_description  article_id  \\\n",
       "0  Detect bad readings in real time using Python ...           0   \n",
       "1  See the forest, see the trees. Here lies the c...           1   \n",
       "2  Here’s this week’s news in Data Science and Bi...           2   \n",
       "3  Learn how distributed DBs solve the problem of...           3   \n",
       "4  This video demonstrates the power of IBM DataS...           4   \n",
       "\n",
       "                                               title  \n",
       "0  Detect Malfunctioning IoT Sensors with Streami...  \n",
       "1  Communicating data science: A guide to present...  \n",
       "2         This Week in Data Science (April 18, 2017)  \n",
       "3  DataLayer Conference: Boost the performance of...  \n",
       "4      Analyze NY Restaurant data using Spark in DSX  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_content.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>user_id</th>\n",
       "      <th>nb_interactions_user_article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  user_id  \\\n",
       "0         593  upload files to ibm data science experience us...        1   \n",
       "1         593  upload files to ibm data science experience us...        2   \n",
       "2         593  upload files to ibm data science experience us...        3   \n",
       "3         593  upload files to ibm data science experience us...        4   \n",
       "4         593  upload files to ibm data science experience us...        5   \n",
       "\n",
       "   nb_interactions_user_article  \n",
       "0                             1  \n",
       "1                             1  \n",
       "2                             2  \n",
       "3                             1  \n",
       "4                             1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of times the user seen the article\n",
    "pre_data = dict(df.groupby(['user_id', 'article_id'])['article_id'].count())\n",
    "\n",
    "list_user = []\n",
    "list_article_id = []\n",
    "list_nb_interactions = []\n",
    "\n",
    "for key, val in pre_data.items():\n",
    "    list_user.append(key[0])\n",
    "    list_article_id.append(key[1])\n",
    "    list_nb_interactions.append(val)\n",
    "    \n",
    "zipped_list = list(zip(list_user, list_article_id, list_nb_interactions))\n",
    "interaction_user = pd.DataFrame(zipped_list, columns=['user_id','article_id','nb_interactions_user_article'])\n",
    "\n",
    "df = pd.merge(df, interaction_user, on=['user_id','article_id'])\n",
    "\n",
    "# The nb interactions was shown implicitly with the number of rows\n",
    "# Now I have information about the number of interactions by creating this column\n",
    "# I can drop duplicated rows\n",
    "df = df.drop_duplicates(keep='first')\n",
    "df = df.reset_index().drop(labels='index', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't have any date of the interraction between user and article, so just for the module, I'll simulate a date field set to 0. Popularity of an item is computed by the weighted rating calcul shown in recommender_function.py, but in case of tie, the more recent date will be first, so by putting a same value for all the records, I'm not influence the importance of an article. Here I chose 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare TFIDF Matrice for Content Based Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    This function do the following steps:\n",
    "    - Normalize, remove ponctuations\n",
    "    - Tokenize the input (str)\n",
    "    - Remove english stopwords\n",
    "    - Lemmatize but keep the gramatical sense of the word\n",
    "    - Clean White spaces\n",
    "    \"\"\"\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "    words = word_tokenize(text)\n",
    "    words = [w for w in words if w not in stopwords.words(\"english\")]\n",
    "    lemmed = [WordNetLemmatizer().lemmatize(w, pos='v') for w in words]\n",
    "    words_clean = [word.strip() for word in words]\n",
    "    return words_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=tokenize, ngram_range=(1, 2))\n",
    "df_content['doc_description'] = df_content['doc_description'].fillna('')\n",
    "tfidf_matrix = tfidf.fit_transform(df_content['doc_description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1056, 17507)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = r.Recommender(df_items=df_content,                            # df that contains all the items with description and more\n",
    "                    df_reviews=df,                                  # df that contains interactions between users and items\n",
    "                    #based_similarity_col='doc_description',         # The column name that you want to based on to compute similarity between items\n",
    "                    item_name_colname='title',                      # The title column of the df (this can be use with the 1st df or the 2nd, that why I wanted the same name for both)\n",
    "                    user_id_colname='user_id',                      # The name of the user id column\n",
    "                    item_id_colname='article_id',                   # The name of the item id column\n",
    "                    rating_col_name='nb_interactions_user_article', # The rating column\n",
    "                    date_col_name='date')                           # The date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create User-Item matrix...\n",
      "Train data with Funk Sigular Value Decomposition...\n",
      "Iterations \t\t Mean Squared Error \n",
      "\t1 \t\t 2.4964122936500592 \n",
      "\t2 \t\t 2.3207887788247876 \n",
      "\t3 \t\t 2.1679583890310745 \n",
      "\t4 \t\t 2.034084338859403 \n",
      "\t5 \t\t 1.9161039259364883 \n",
      "\t6 \t\t 1.811549855757542 \n",
      "\t7 \t\t 1.718417371258855 \n",
      "\t8 \t\t 1.6350643805981449 \n",
      "\t9 \t\t 1.5601356397025377 \n",
      "\t10 \t\t 1.4925046604766596 \n"
     ]
    }
   ],
   "source": [
    "rec.fit(iters=10, latent_features=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### investigate the user-Item matrix created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>article_id</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>12</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>18</th>\n",
       "      <th>...</th>\n",
       "      <th>1028</th>\n",
       "      <th>1030</th>\n",
       "      <th>1035</th>\n",
       "      <th>1038</th>\n",
       "      <th>1042</th>\n",
       "      <th>1043</th>\n",
       "      <th>1044</th>\n",
       "      <th>1047</th>\n",
       "      <th>1048</th>\n",
       "      <th>1050</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 437 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "article_id  0     2     4     8     9     12    14    15    16    18    ...   \\\n",
       "user_id                                                                 ...    \n",
       "1            NaN   NaN   NaN   NaN   NaN   NaN   1.0   NaN   NaN   NaN  ...    \n",
       "2            NaN   NaN   NaN   NaN   NaN   1.0   NaN   NaN   NaN   NaN  ...    \n",
       "3            NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "4            NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "5            NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "\n",
       "article_id  1028  1030  1035  1038  1042  1043  1044  1047  1048  1050  \n",
       "user_id                                                                 \n",
       "1            NaN   NaN   NaN   NaN   1.0   NaN   NaN   1.0   NaN   NaN  \n",
       "2            NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3            NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4            NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "5            NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[5 rows x 437 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec.user_item_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get some Infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb of users: 4258\n",
      "Nb of items: 437\n",
      "The user_id with the highest avg rating given: 1102\n",
      "The article_id with the highest avg rating received: 50\n",
      "The article name with the highest avg rating received: Graph-based machine learning\n",
      "Shape of the U matrix: (4258, 10)\n",
      "Shape of the V(transpose) matrix: (10, 437)\n"
     ]
    }
   ],
   "source": [
    "def info():\n",
    "    user_item = rec.user_item_df\n",
    "    nb_user = rec.n_users\n",
    "    nb_items = rec.n_items\n",
    "    item_name = rec.item_name_colname\n",
    "    item_id = rec.item_id_colname\n",
    "    u_mat = rec.user_mat\n",
    "    i_mat = rec.item_mat\n",
    "    user_high_rate = list(dict(user_item.mean(axis=1).sort_values(ascending=False).head(1)).keys())[0]\n",
    "    movie_id_high_rate = list(dict(user_item.mean(axis=0).sort_values(ascending=False).head(1)).keys())[0]\n",
    "    movie_name_high_rate = tuple(df_content[df_content[item_id] == movie_id_high_rate][item_name])[0]\n",
    "    \n",
    "\n",
    "    print(f\"Nb of users: {nb_user}\")\n",
    "    print(f\"Nb of items: {nb_items}\")\n",
    "    print(f\"The user_id with the highest avg rating given: {user_high_rate}\")\n",
    "    print(f\"The article_id with the highest avg rating received: {movie_id_high_rate}\")\n",
    "    print(f\"The article name with the highest avg rating received: {movie_name_high_rate}\")\n",
    "    print(f\"Shape of the U matrix: {u_mat.shape}\")\n",
    "    print(f\"Shape of the V(transpose) matrix: {i_mat.shape}\")\n",
    "\n",
    "info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "##### To make recommendation: given a user id we want to find similar users to this user in order to recommend items. Similarity are found by computing the dot product of characteristics of the user with its transpose, the more the result of an user-user pair is high, the more they have in common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_similarity = rec.user_item_df.reset_index().replace(np.nan, 0)\n",
    "def prep_get_similar_user():\n",
    "    user_content = np.array(df_user_similarity.iloc[:,1:])\n",
    "    user_content_transpose = np.transpose(user_content)\n",
    "    dot_prod = user_content.dot(user_content_transpose)\n",
    "    return dot_prod\n",
    "\n",
    "dot_product_matrix_user = prep_get_similar_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare a function to display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_recommendations(rec_ids, rec_names, message, rec_ids_users, rec_user_articles):\n",
    "    \n",
    "    if type(rec_ids) == type(None):\n",
    "        print(f\"{message}\")\n",
    "    \n",
    "    else:\n",
    "        dict_id_name = dict(zip(rec_ids, rec_names))\n",
    "        \n",
    "        if type(rec_ids_users) != type(None):\n",
    "            print('Matrix Factorisation SVD:')\n",
    "            print(f\"\\t{message}\")\n",
    "            \n",
    "            for key, val  in dict_id_name.items():\n",
    "                print(f\"\\t- ID items: {key}\")\n",
    "                print(f\"\\tName: {val}\\n\")\n",
    "\n",
    "            print('CF User Based:')\n",
    "            print('\\tUser that are similar to you also seen:\\n')\n",
    "            for i in rec_user_articles[:5]:\n",
    "                print(f\"\\t- {i}\")\n",
    "        else:\n",
    "            print(f\"\\t{message}\")\n",
    "            dict_id_name = dict(zip(rec_ids, rec_names))\n",
    "            for key, val  in dict_id_name.items():\n",
    "                print(f\"\\t- ID items: {key}\")\n",
    "                print(f\"\\tName: {val}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Existing user\n",
    "\n",
    "- Because it is an existing user, recommendations are made using FunkSVD (matrix factorisation), it will predict the rating it will give to all items and get back the items associate with the the top predicted rate. The dot_product_matrix will not be used but is requiered in case of you want to find a similar item to another instead of finding best item for a user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Factorisation SVD:\n",
      "\tGlad to see you again! recommended for you:\n",
      "\n",
      "\t- ID items: 973\n",
      "\tName: Recent trends in recommender systems\n",
      "\n",
      "\t- ID items: 984\n",
      "\tName: The Data Processing Inequality\n",
      "\n",
      "\t- ID items: 346\n",
      "\tName: Fighting Gerrymandering: Using data science to draw fairer congressional districts\n",
      "\n",
      "\t- ID items: 195\n",
      "\tName: Artificial Intelligence, Ethically Speaking – Inside Machine learning – Medium\n",
      "\n",
      "\t- ID items: 626\n",
      "\tName: Analyze Db2 Warehouse on Cloud data in RStudio in DSX\n",
      "\n",
      "CF User Based:\n",
      "\tUser that are similar to you also seen:\n",
      "\n",
      "\t- upload files to ibm data science experience using the command line\n"
     ]
    }
   ],
   "source": [
    "rec_ids, rec_names, message, rec_ids_users, rec_user_articles = rec.make_recommendations(_id=3,\n",
    "                                                                                         dot_prod_user= dot_product_matrix_user,\n",
    "                                                                                         tfidf_matrix=tfidf_matrix,\n",
    "                                                                                         _id_type='user',\n",
    "                                                                                         rec_num=5)\n",
    "display_recommendations(rec_ids, rec_names, message, rec_ids_users, rec_user_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### New User\n",
    "\n",
    "- Because it is new user, recommendations are given using ranked based method, which simply return back the most popular items according to the ratings given by users, the number of ratings, the recency of the ratings. The dot_product_matrix will not be used but is requiered in case of you want to find a similar item to another instead of finding best item for a user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked Based:\n",
      "\tHey, you are new here, this is for you:\n",
      "\n",
      "\t- ID items: 221\n",
      "\tName: How smart catalogs can turn the big data flood into an ocean of opportunity\n",
      "\n",
      "\t- ID items: 50\n",
      "\tName: Graph-based machine learning\n",
      "\n",
      "\t- ID items: 232\n",
      "\tName: Self-service data preparation with IBM Data Refinery\n",
      "\n",
      "\t- ID items: 43\n",
      "\tName: Deep Learning With Tensorflow Course by Big Data University\n",
      "\n",
      "\t- ID items: 732\n",
      "\tName: Rapidly build Machine Learning flows with DSX\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec_ids, rec_names, message, rec_ids_users, rec_user_articles = rec.make_recommendations(_id=8000,\n",
    "                                                                                         dot_prod_user= dot_product_matrix_user,\n",
    "                                                                                         tfidf_matrix=tfidf_matrix,\n",
    "                                                                                         _id_type='user',\n",
    "                                                                                         rec_num=5)\n",
    "\n",
    "print('Ranked Based:')\n",
    "display_recommendations(rec_ids, rec_names, message, rec_ids_users, rec_user_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "#### Existing items\n",
    "\n",
    "- Here we enter an item id and would like to find similar items using the dot_product_matrix computed earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content Based:\n",
      "\tSimilar items for id:593, corresponding to Upload Files to IBM Data Science Experience Using the Command Line:\n",
      "\n",
      "\t- ID items: 593\n",
      "\tName: Upload Files to IBM Data Science Experience Using the Command Line\n",
      "\n",
      "\t- ID items: 600\n",
      "\tName: Access IBM Analytics for Apache Spark from RStudio\n",
      "\n",
      "\t- ID items: 809\n",
      "\tName: Use the Machine Learning Library\n",
      "\n",
      "\t- ID items: 161\n",
      "\tName: Use the Machine Learning Library in Spark\n",
      "\n",
      "\t- ID items: 893\n",
      "\tName: Use the Machine Learning Library in IBM Analytics for Apache Spark\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec_ids, rec_names, message, rec_ids_users, rec_user_articles = rec.make_recommendations(_id=593,\n",
    "                                                                                         dot_prod_user= dot_product_matrix_user,\n",
    "                                                                                         tfidf_matrix=tfidf_matrix,\n",
    "                                                                                         _id_type='item',\n",
    "                                                                                         rec_num=5)\n",
    "print('Content Based:')\n",
    "display_recommendations(rec_ids, rec_names, message, rec_ids_users, rec_user_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulate an error by passing a non existing item id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can't make recommendation for this item, please makesure the data was updated with this item.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec_ids, rec_names, message, rec_ids_users, rec_user_articles = rec.make_recommendations(_id=1087630,\n",
    "                                                                                         dot_prod_user= dot_product_matrix_user,\n",
    "                                                                                         tfidf_matrix=tfidf_matrix,\n",
    "                                                                                         _id_type='item',\n",
    "                                                                                         rec_num=5)\n",
    "\n",
    "\n",
    "display_recommendations(rec_ids, rec_names, message, rec_ids_users, rec_user_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imagine that we have an article that we want to promote, but we want the top 10 users who may interested by this offer, the item id is 984."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These users may interested by this item:\n",
      "- 3951\n",
      "- 2759\n",
      "- 1549\n",
      "- 3445\n",
      "- 2457\n",
      "- 927\n",
      "- 3580\n",
      "- 2489\n",
      "- 3161\n",
      "- 3947\n"
     ]
    }
   ],
   "source": [
    "user_item = rec.user_item_df\n",
    "def may_interested_by(item_id, top_n=10):\n",
    "    pred = {}\n",
    "    # iterate over each users and predict the rate it will give to this movie\n",
    "    for user in user_item.index:\n",
    "        pred[user] = rec.predict_rating(user_id=user, item_id=item_id)\n",
    "\n",
    "    top_10_pairs = sorted(pred.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    top_10_user_ids = []\n",
    "\n",
    "    for i in top_10_pairs:\n",
    "        top_10_user_ids.append(i[0])\n",
    "\n",
    "    return top_10_user_ids\n",
    "\n",
    "print('These users may interested by this item:')\n",
    "for i in may_interested_by(984, 10):\n",
    "    print(f\"- {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
