{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Cleaning steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import recommender as r\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('user-item-interactions.csv')\n",
    "df_content = pd.read_csv('articles_community.csv')\n",
    "del df['Unnamed: 0']\n",
    "del df_content['Unnamed: 0']\n",
    "\n",
    "# make sure all articles from df are in df_content\n",
    "df = pd.merge(df, df_content[['article_id']], on='article_id', how='inner')\n",
    "\n",
    "df_content = df_content.drop(labels='doc_status', axis=1)\n",
    "df_content = df_content.drop_duplicates()\n",
    "\n",
    "#df = df.replace('no_email', np.nan)\n",
    "\n",
    "def email_mapper():\n",
    "    coded_dict = dict()\n",
    "    cter = 1\n",
    "    email_encoded = []\n",
    "    \n",
    "    for val in df['email']:\n",
    "        if val not in coded_dict:\n",
    "            coded_dict[val] = cter\n",
    "            cter+=1\n",
    "        \n",
    "        email_encoded.append(coded_dict[val])\n",
    "    return email_encoded\n",
    "\n",
    "email_encoded = email_mapper()\n",
    "del df['email']\n",
    "df['user_id'] = email_encoded\n",
    "\n",
    "# Rename my article name field to be the same in both dfs\n",
    "df_content['title'] = df_content['doc_full_name']\n",
    "df_content = df_content.drop(labels='doc_full_name', axis=1)\n",
    "\n",
    "df.article_id = df.article_id.astype('int64')\n",
    "df_content.article_id = df_content.article_id.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  user_id\n",
       "0         593  upload files to ibm data science experience us...        1\n",
       "1         593  upload files to ibm data science experience us...        2\n",
       "2         593  upload files to ibm data science experience us...        3\n",
       "3         593  upload files to ibm data science experience us...        4\n",
       "4         593  upload files to ibm data science experience us...        3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>Detect bad readings in real time using Python ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Detect Malfunctioning IoT Sensors with Streami...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...</td>\n",
       "      <td>See the forest, see the trees. Here lies the c...</td>\n",
       "      <td>1</td>\n",
       "      <td>Communicating data science: A guide to present...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...</td>\n",
       "      <td>Here’s this week’s news in Data Science and Bi...</td>\n",
       "      <td>2</td>\n",
       "      <td>This Week in Data Science (April 18, 2017)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...</td>\n",
       "      <td>Learn how distributed DBs solve the problem of...</td>\n",
       "      <td>3</td>\n",
       "      <td>DataLayer Conference: Boost the performance of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>This video demonstrates the power of IBM DataS...</td>\n",
       "      <td>4</td>\n",
       "      <td>Analyze NY Restaurant data using Spark in DSX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            doc_body  \\\n",
       "0  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "1  No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...   \n",
       "2  ☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...   \n",
       "3  DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...   \n",
       "4  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "\n",
       "                                     doc_description  article_id  \\\n",
       "0  Detect bad readings in real time using Python ...           0   \n",
       "1  See the forest, see the trees. Here lies the c...           1   \n",
       "2  Here’s this week’s news in Data Science and Bi...           2   \n",
       "3  Learn how distributed DBs solve the problem of...           3   \n",
       "4  This video demonstrates the power of IBM DataS...           4   \n",
       "\n",
       "                                               title  \n",
       "0  Detect Malfunctioning IoT Sensors with Streami...  \n",
       "1  Communicating data science: A guide to present...  \n",
       "2         This Week in Data Science (April 18, 2017)  \n",
       "3  DataLayer Conference: Boost the performance of...  \n",
       "4      Analyze NY Restaurant data using Spark in DSX  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_content.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Engineering the feature Using NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>insights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>Detect bad readings in real time using Python ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Detect Malfunctioning IoT Sensors with Streami...</td>\n",
       "      <td>detect,malfunctioning,iot,streaming,analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...</td>\n",
       "      <td>See the forest, see the trees. Here lies the c...</td>\n",
       "      <td>1</td>\n",
       "      <td>Communicating data science: A guide to present...</td>\n",
       "      <td>data,science,work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...</td>\n",
       "      <td>Here’s this week’s news in Data Science and Bi...</td>\n",
       "      <td>2</td>\n",
       "      <td>This Week in Data Science (April 18, 2017)</td>\n",
       "      <td>data,science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...</td>\n",
       "      <td>Learn how distributed DBs solve the problem of...</td>\n",
       "      <td>3</td>\n",
       "      <td>DataLayer Conference: Boost the performance of...</td>\n",
       "      <td>datalayer,performance,database</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>This video demonstrates the power of IBM DataS...</td>\n",
       "      <td>4</td>\n",
       "      <td>Analyze NY Restaurant data using Spark in DSX</td>\n",
       "      <td>analyze,ny,restaurant,spark,dsx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            doc_body  \\\n",
       "0  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "1  No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...   \n",
       "2  ☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...   \n",
       "3  DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...   \n",
       "4  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "\n",
       "                                     doc_description  article_id  \\\n",
       "0  Detect bad readings in real time using Python ...           0   \n",
       "1  See the forest, see the trees. Here lies the c...           1   \n",
       "2  Here’s this week’s news in Data Science and Bi...           2   \n",
       "3  Learn how distributed DBs solve the problem of...           3   \n",
       "4  This video demonstrates the power of IBM DataS...           4   \n",
       "\n",
       "                                               title  \\\n",
       "0  Detect Malfunctioning IoT Sensors with Streami...   \n",
       "1  Communicating data science: A guide to present...   \n",
       "2         This Week in Data Science (April 18, 2017)   \n",
       "3  DataLayer Conference: Boost the performance of...   \n",
       "4      Analyze NY Restaurant data using Spark in DSX   \n",
       "\n",
       "                                        insights  \n",
       "0  detect,malfunctioning,iot,streaming,analytics  \n",
       "1                              data,science,work  \n",
       "2                                   data,science  \n",
       "3                 datalayer,performance,database  \n",
       "4                analyze,ny,restaurant,spark,dsx  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nlp_task(data):\n",
    "    sent = data\n",
    "    doc=nlp(sent)\n",
    "    sub_toks = [tok for tok in doc if ((tok.dep_ == \"compound\") or (tok.dep_ == \"dobj\") or (tok.dep_ == \"pobj\")) ]\n",
    "    insight_words = [str(i).lower() for i in sub_toks]\n",
    "    insight_words = ','.join(insight_words)\n",
    "    return insight_words\n",
    "\n",
    "df_content['insights'] = df_content.title.apply(nlp_task)\n",
    "df_content.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create list of insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "insights_list = []\n",
    "\n",
    "for i in df_content.insights:\n",
    "    try:\n",
    "        insights_list.extend(i.split(','))\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "#normalize\n",
    "insights_list = [i.lower() for i in insights_list]\n",
    "\n",
    "#remove all non character from the list\n",
    "regex = re.compile('[^a-zA-Z]')\n",
    "insights_list = [regex.sub('non_charac', i) for i in insights_list]\n",
    "insights_list = set(insights_list)\n",
    "insights_list.remove('non_charac')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fill df_content with columns of insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_insights(val):\n",
    "    try:\n",
    "        if val.find(insight) > -1:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except AttributeError:\n",
    "        return 0\n",
    "    \n",
    "for insight in insights_list:\n",
    "    df_content[insight] = df_content['insights'].apply(split_insights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>scala</th>\n",
       "      <th>queries</th>\n",
       "      <th>seium</th>\n",
       "      <th>traffic</th>\n",
       "      <th>recommendation</th>\n",
       "      <th>dinesh</th>\n",
       "      <th>examples</th>\n",
       "      <th>eye</th>\n",
       "      <th>...</th>\n",
       "      <th>random</th>\n",
       "      <th>full</th>\n",
       "      <th>sets</th>\n",
       "      <th>red</th>\n",
       "      <th>chronic</th>\n",
       "      <th>tidyr</th>\n",
       "      <th>pis</th>\n",
       "      <th>simple</th>\n",
       "      <th>sector</th>\n",
       "      <th>web</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Detect Malfunctioning IoT Sensors with Streami...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Communicating data science: A guide to present...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>This Week in Data Science (April 18, 2017)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>DataLayer Conference: Boost the performance of...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Analyze NY Restaurant data using Spark in DSX</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1060 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  scala  \\\n",
       "0           0  Detect Malfunctioning IoT Sensors with Streami...      0   \n",
       "1           1  Communicating data science: A guide to present...      0   \n",
       "2           2         This Week in Data Science (April 18, 2017)      0   \n",
       "3           3  DataLayer Conference: Boost the performance of...      0   \n",
       "4           4      Analyze NY Restaurant data using Spark in DSX      0   \n",
       "\n",
       "   queries  seium  traffic  recommendation  dinesh  examples  eye ...   \\\n",
       "0        0      0        0               0       0         0    0 ...    \n",
       "1        0      0        0               0       0         0    0 ...    \n",
       "2        0      0        0               0       0         0    0 ...    \n",
       "3        0      0        0               0       0         0    0 ...    \n",
       "4        0      0        0               0       0         0    0 ...    \n",
       "\n",
       "   random  full  sets  red  chronic  tidyr  pis  simple  sector  web  \n",
       "0       0     0     0    0        0      0    0       0       0    0  \n",
       "1       0     0     0    0        0      0    0       0       0    0  \n",
       "2       0     0     0    0        0      0    0       0       0    0  \n",
       "3       0     0     0    0        0      0    0       0       0    0  \n",
       "4       0     0     0    0        0      0    0       0       0    0  \n",
       "\n",
       "[5 rows x 1060 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove some columns\n",
    "df_content = df_content.drop(labels=['insights', 'doc_body', 'doc_description', ''], axis=1)\n",
    "\n",
    "df_content.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>user_id</th>\n",
       "      <th>nb_interactions_user_article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  user_id  \\\n",
       "0         593  upload files to ibm data science experience us...        1   \n",
       "1         593  upload files to ibm data science experience us...        2   \n",
       "2         593  upload files to ibm data science experience us...        3   \n",
       "3         593  upload files to ibm data science experience us...        4   \n",
       "4         593  upload files to ibm data science experience us...        5   \n",
       "\n",
       "   nb_interactions_user_article  \n",
       "0                             1  \n",
       "1                             1  \n",
       "2                             2  \n",
       "3                             1  \n",
       "4                             1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of times the user seen the article\n",
    "pre_data = dict(df.groupby(['user_id', 'article_id'])['article_id'].count())\n",
    "\n",
    "list_user = []\n",
    "list_article_id = []\n",
    "list_nb_interactions = []\n",
    "\n",
    "for key, val in pre_data.items():\n",
    "    list_user.append(key[0])\n",
    "    list_article_id.append(key[1])\n",
    "    list_nb_interactions.append(val)\n",
    "    \n",
    "zipped_list = list(zip(list_user, list_article_id, list_nb_interactions))\n",
    "interaction_user = pd.DataFrame(zipped_list, columns=['user_id','article_id','nb_interactions_user_article'])\n",
    "\n",
    "df = pd.merge(df, interaction_user, on=['user_id','article_id'])\n",
    "\n",
    "# The nb interactions was shown implicitly with the number of rows\n",
    "# Now I have information about the number of interactions by creating this column\n",
    "# I can drop duplicated rows\n",
    "df = df.drop_duplicates(keep='first')\n",
    "df = df.reset_index().drop(labels='index', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>user_id</th>\n",
       "      <th>nb_interactions_user_article</th>\n",
       "      <th>nb_views_of_the_article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  user_id  \\\n",
       "0         593  upload files to ibm data science experience us...        1   \n",
       "1         593  upload files to ibm data science experience us...        2   \n",
       "2         593  upload files to ibm data science experience us...        3   \n",
       "3         593  upload files to ibm data science experience us...        4   \n",
       "4         593  upload files to ibm data science experience us...        5   \n",
       "\n",
       "   nb_interactions_user_article  nb_views_of_the_article  \n",
       "0                             1                      108  \n",
       "1                             1                      108  \n",
       "2                             2                      108  \n",
       "3                             1                      108  \n",
       "4                             1                      108  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "art_nb_inter = dict(df.groupby('article_id')['nb_interactions_user_article'].count())\n",
    "df['nb_views_of_the_article'] = df.article_id.map(art_nb_inter)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>user_id</th>\n",
       "      <th>nb_interactions_user_article</th>\n",
       "      <th>nb_views_of_the_article</th>\n",
       "      <th>avg_nb_interactions_of_the_article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>1.185185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>1.185185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1.185185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>1.185185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>1.185185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  user_id  \\\n",
       "0         593  upload files to ibm data science experience us...        1   \n",
       "1         593  upload files to ibm data science experience us...        2   \n",
       "2         593  upload files to ibm data science experience us...        3   \n",
       "3         593  upload files to ibm data science experience us...        4   \n",
       "4         593  upload files to ibm data science experience us...        5   \n",
       "\n",
       "   nb_interactions_user_article  nb_views_of_the_article  \\\n",
       "0                             1                      108   \n",
       "1                             1                      108   \n",
       "2                             2                      108   \n",
       "3                             1                      108   \n",
       "4                             1                      108   \n",
       "\n",
       "   avg_nb_interactions_of_the_article  \n",
       "0                            1.185185  \n",
       "1                            1.185185  \n",
       "2                            1.185185  \n",
       "3                            1.185185  \n",
       "4                            1.185185  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_nb_interactions_of_the_article = dict(df.groupby('article_id')['nb_interactions_user_article'].mean())\n",
    "df['avg_nb_interactions_of_the_article'] = df.article_id.map(avg_nb_interactions_of_the_article)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>user_id</th>\n",
       "      <th>nb_interactions_user_article</th>\n",
       "      <th>nb_views_of_the_article</th>\n",
       "      <th>avg_nb_interactions_of_the_article</th>\n",
       "      <th>rank_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>1.185185</td>\n",
       "      <td>1.197335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>1.185185</td>\n",
       "      <td>1.197335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1.185185</td>\n",
       "      <td>1.197335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>1.185185</td>\n",
       "      <td>1.197335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>1.185185</td>\n",
       "      <td>1.197335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  user_id  \\\n",
       "0         593  upload files to ibm data science experience us...        1   \n",
       "1         593  upload files to ibm data science experience us...        2   \n",
       "2         593  upload files to ibm data science experience us...        3   \n",
       "3         593  upload files to ibm data science experience us...        4   \n",
       "4         593  upload files to ibm data science experience us...        5   \n",
       "\n",
       "   nb_interactions_user_article  nb_views_of_the_article  \\\n",
       "0                             1                      108   \n",
       "1                             1                      108   \n",
       "2                             2                      108   \n",
       "3                             1                      108   \n",
       "4                             1                      108   \n",
       "\n",
       "   avg_nb_interactions_of_the_article  rank_score  \n",
       "0                            1.185185    1.197335  \n",
       "1                            1.185185    1.197335  \n",
       "2                            1.185185    1.197335  \n",
       "3                            1.185185    1.197335  \n",
       "4                            1.185185    1.197335  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute Weighted rate\n",
    "\n",
    "v = df.nb_views_of_the_article\n",
    "m = df.nb_views_of_the_article.quantile(0.80)\n",
    "R = df.avg_nb_interactions_of_the_article\n",
    "C = df.nb_interactions_user_article.mean()\n",
    "\n",
    "df['rank_score'] = (v/(v+m) * R) + (m/(m+v) * C)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[221,\n",
       " 50,\n",
       " 232,\n",
       " 43,\n",
       " 651,\n",
       " 732,\n",
       " 12,\n",
       " 29,\n",
       " 943,\n",
       " 237,\n",
       " 108,\n",
       " 510,\n",
       " 213,\n",
       " 486,\n",
       " 398,\n",
       " 684,\n",
       " 977,\n",
       " 725,\n",
       " 969,\n",
       " 542,\n",
       " 241,\n",
       " 268,\n",
       " 20,\n",
       " 251,\n",
       " 353,\n",
       " 1016,\n",
       " 409,\n",
       " 1018,\n",
       " 600,\n",
       " 936,\n",
       " 729,\n",
       " 448,\n",
       " 477,\n",
       " 390,\n",
       " 865,\n",
       " 250,\n",
       " 910,\n",
       " 812,\n",
       " 33,\n",
       " 795,\n",
       " 437,\n",
       " 1028,\n",
       " 366,\n",
       " 151,\n",
       " 606,\n",
       " 686,\n",
       " 681,\n",
       " 557,\n",
       " 607,\n",
       " 369,\n",
       " 793,\n",
       " 2,\n",
       " 673,\n",
       " 891,\n",
       " 844,\n",
       " 933,\n",
       " 730,\n",
       " 428,\n",
       " 751,\n",
       " 722,\n",
       " 240,\n",
       " 645,\n",
       " 705,\n",
       " 1000,\n",
       " 949,\n",
       " 1008,\n",
       " 1025,\n",
       " 678,\n",
       " 164,\n",
       " 825,\n",
       " 641,\n",
       " 766,\n",
       " 655,\n",
       " 109,\n",
       " 53,\n",
       " 555,\n",
       " 521,\n",
       " 429,\n",
       " 609,\n",
       " 122,\n",
       " 930,\n",
       " 316,\n",
       " 588,\n",
       " 679,\n",
       " 788,\n",
       " 362,\n",
       " 323,\n",
       " 760,\n",
       " 1050,\n",
       " 876,\n",
       " 534,\n",
       " 1038,\n",
       " 857,\n",
       " 517,\n",
       " 961,\n",
       " 853,\n",
       " 616,\n",
       " 303,\n",
       " 153,\n",
       " 482,\n",
       " 887,\n",
       " 965,\n",
       " 76,\n",
       " 355,\n",
       " 302,\n",
       " 881,\n",
       " 463,\n",
       " 749,\n",
       " 299,\n",
       " 846,\n",
       " 399,\n",
       " 668,\n",
       " 492,\n",
       " 422,\n",
       " 724,\n",
       " 653,\n",
       " 662,\n",
       " 417,\n",
       " 984,\n",
       " 974,\n",
       " 675,\n",
       " 404,\n",
       " 903,\n",
       " 444,\n",
       " 412,\n",
       " 508,\n",
       " 346,\n",
       " 124,\n",
       " 870,\n",
       " 972,\n",
       " 940,\n",
       " 364,\n",
       " 575,\n",
       " 708,\n",
       " 384,\n",
       " 636,\n",
       " 778,\n",
       " 443,\n",
       " 758,\n",
       " 430,\n",
       " 416,\n",
       " 644,\n",
       " 757,\n",
       " 677,\n",
       " 947,\n",
       " 499,\n",
       " 504,\n",
       " 376,\n",
       " 586,\n",
       " 379,\n",
       " 935,\n",
       " 544,\n",
       " 0,\n",
       " 266,\n",
       " 194,\n",
       " 996,\n",
       " 631,\n",
       " 363,\n",
       " 395,\n",
       " 375,\n",
       " 880,\n",
       " 98,\n",
       " 78,\n",
       " 420,\n",
       " 985,\n",
       " 800,\n",
       " 997,\n",
       " 610,\n",
       " 389,\n",
       " 884,\n",
       " 740,\n",
       " 553,\n",
       " 1043,\n",
       " 701,\n",
       " 532,\n",
       " 626,\n",
       " 181,\n",
       " 667,\n",
       " 193,\n",
       " 120,\n",
       " 116,\n",
       " 855,\n",
       " 411,\n",
       " 381,\n",
       " 522,\n",
       " 474,\n",
       " 1015,\n",
       " 564,\n",
       " 805,\n",
       " 669,\n",
       " 103,\n",
       " 563,\n",
       " 1035,\n",
       " 502,\n",
       " 763,\n",
       " 714,\n",
       " 941,\n",
       " 351,\n",
       " 647,\n",
       " 593,\n",
       " 80,\n",
       " 475,\n",
       " 986,\n",
       " 188,\n",
       " 1004,\n",
       " 906,\n",
       " 96,\n",
       " 464,\n",
       " 843,\n",
       " 112,\n",
       " 277,\n",
       " 1030,\n",
       " 567,\n",
       " 515,\n",
       " 446,\n",
       " 967,\n",
       " 622,\n",
       " 215,\n",
       " 695,\n",
       " 100,\n",
       " 330,\n",
       " 473,\n",
       " 183,\n",
       " 973,\n",
       " 809,\n",
       " 254,\n",
       " 659,\n",
       " 468,\n",
       " 524,\n",
       " 145,\n",
       " 210,\n",
       " 189,\n",
       " 919,\n",
       " 134,\n",
       " 9,\n",
       " 400,\n",
       " 896,\n",
       " 256,\n",
       " 948,\n",
       " 926,\n",
       " 781,\n",
       " 117,\n",
       " 383,\n",
       " 955,\n",
       " 278,\n",
       " 65,\n",
       " 547,\n",
       " 892,\n",
       " 455,\n",
       " 491,\n",
       " 682,\n",
       " 479,\n",
       " 373,\n",
       " 77,\n",
       " 932,\n",
       " 48,\n",
       " 58,\n",
       " 864,\n",
       " 39,\n",
       " 495,\n",
       " 176,\n",
       " 500,\n",
       " 82,\n",
       " 862,\n",
       " 715,\n",
       " 759,\n",
       " 784,\n",
       " 735,\n",
       " 656,\n",
       " 871,\n",
       " 59,\n",
       " 157,\n",
       " 356,\n",
       " 4,\n",
       " 868,\n",
       " 727,\n",
       " 528,\n",
       " 427,\n",
       " 314,\n",
       " 143,\n",
       " 585,\n",
       " 928,\n",
       " 1042,\n",
       " 260,\n",
       " 146,\n",
       " 1006,\n",
       " 18,\n",
       " 440,\n",
       " 813,\n",
       " 525,\n",
       " 311,\n",
       " 319,\n",
       " 258,\n",
       " 25,\n",
       " 426,\n",
       " 313,\n",
       " 113,\n",
       " 951,\n",
       " 107,\n",
       " 470,\n",
       " 51,\n",
       " 692,\n",
       " 1017,\n",
       " 115,\n",
       " 480,\n",
       " 270,\n",
       " 60,\n",
       " 233,\n",
       " 670,\n",
       " 975,\n",
       " 583,\n",
       " 693,\n",
       " 30,\n",
       " 125,\n",
       " 559,\n",
       " 761,\n",
       " 723,\n",
       " 81,\n",
       " 298,\n",
       " 680,\n",
       " 882,\n",
       " 569,\n",
       " 36,\n",
       " 87,\n",
       " 720,\n",
       " 632,\n",
       " 785,\n",
       " 291,\n",
       " 324,\n",
       " 721,\n",
       " 939,\n",
       " 962,\n",
       " 634,\n",
       " 821,\n",
       " 352,\n",
       " 993,\n",
       " 339,\n",
       " 1044,\n",
       " 462,\n",
       " 968,\n",
       " 239,\n",
       " 359,\n",
       " 618,\n",
       " 54,\n",
       " 234,\n",
       " 460,\n",
       " 315,\n",
       " 195,\n",
       " 599,\n",
       " 62,\n",
       " 297,\n",
       " 833,\n",
       " 494,\n",
       " 465,\n",
       " 138,\n",
       " 347,\n",
       " 28,\n",
       " 566,\n",
       " 858,\n",
       " 101,\n",
       " 658,\n",
       " 252,\n",
       " 348,\n",
       " 485,\n",
       " 1047,\n",
       " 136,\n",
       " 110,\n",
       " 273,\n",
       " 89,\n",
       " 367,\n",
       " 284,\n",
       " 905,\n",
       " 92,\n",
       " 288,\n",
       " 329,\n",
       " 952,\n",
       " 665,\n",
       " 15,\n",
       " 990,\n",
       " 184,\n",
       " 130,\n",
       " 16,\n",
       " 861,\n",
       " 878,\n",
       " 295,\n",
       " 236,\n",
       " 26,\n",
       " 64,\n",
       " 768,\n",
       " 958,\n",
       " 142,\n",
       " 224,\n",
       " 40,\n",
       " 782,\n",
       " 102,\n",
       " 68,\n",
       " 617,\n",
       " 263,\n",
       " 132,\n",
       " 225,\n",
       " 158,\n",
       " 283,\n",
       " 152,\n",
       " 1024,\n",
       " 744,\n",
       " 131,\n",
       " 191,\n",
       " 230,\n",
       " 337,\n",
       " 310,\n",
       " 336,\n",
       " 32,\n",
       " 1048,\n",
       " 1014,\n",
       " 244,\n",
       " 911,\n",
       " 764,\n",
       " 898,\n",
       " 205,\n",
       " 34,\n",
       " 350,\n",
       " 382,\n",
       " 202,\n",
       " 253,\n",
       " 57,\n",
       " 959,\n",
       " 415,\n",
       " 981,\n",
       " 111,\n",
       " 74,\n",
       " 223,\n",
       " 957,\n",
       " 8,\n",
       " 349,\n",
       " 162,\n",
       " 173,\n",
       " 14]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked = df.sort_values(by=['rank_score'], ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think a user-user CF is more interested, because we can't have ratings, so we can just say that a user is interested by an article only if he\n",
    "has interacted with it.\n",
    "So the whole interactions in the dataset means (OK I'm interested).\n",
    "\n",
    "So by now, I'll create a col called interacted full of 1.\n",
    "When the user-item matrix will be create, we will get a matrice with value 1 if a user has interacted with an article\n",
    "np.nan otherwise.\n",
    "\n",
    "I don't have any date of interraction, so just for the module, I'll simulate a date field set to 0. Popularity of an item is based on ratings, then number of rating, then, the recency on the rating. By given a date field set to the same number for all observations, the popularity of the item is not influenced by a fake date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['interacted'] = 1\n",
    "#df['date'] = 0\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = r.Recommender(df_items=df_content,          # df that contains all the items with description and more\n",
    "                    df_reviews=df,                # df that contains interactions between users and items\n",
    "                    item_name_colname='title',    # The title column of the df (this can be use with the 1st df or the 2nd, that why I wanted the same name for both)\n",
    "                    user_id_colname='user_id',    # The name of the user id column\n",
    "                    item_id_colname='article_id', # The name of the item id column\n",
    "                    rating_col_name='interacted', # The rating column\n",
    "                    date_col_name='date')         # The date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create User-Item matrix...\n",
      "Train data with Funk Sigular Value Decomposition...\n",
      "Iterations \t\t Mean Squared Error \n",
      "\t1 \t\t 2.729241626990958 \n",
      "\t2 \t\t 2.4508568219698725 \n",
      "\t3 \t\t 2.217445275518026 \n",
      "\t4 \t\t 2.019644867064396 \n",
      "\t5 \t\t 1.8503764478111702 \n",
      "\t6 \t\t 1.7042216616859707 \n",
      "\t7 \t\t 1.5769862751279797 \n",
      "\t8 \t\t 1.465389066539344 \n",
      "\t9 \t\t 1.3668372158608009 \n",
      "\t10 \t\t 1.2792622134197655 \n",
      "\t11 \t\t 1.20099869049061 \n",
      "\t12 \t\t 1.130694060855732 \n",
      "\t13 \t\t 1.0672405207644828 \n",
      "\t14 \t\t 1.0097234338216763 \n",
      "\t15 \t\t 0.9573818320541022 \n",
      "\t16 \t\t 0.9095779518561473 \n",
      "\t17 \t\t 0.8657735602633064 \n",
      "\t18 \t\t 0.8255114227699649 \n",
      "\t19 \t\t 0.7884006920953767 \n",
      "\t20 \t\t 0.7541053076878689 \n",
      "\t21 \t\t 0.7223347225278133 \n",
      "\t22 \t\t 0.6928364406800697 \n",
      "\t23 \t\t 0.6653899727093928 \n",
      "\t24 \t\t 0.6398019082948521 \n",
      "\t25 \t\t 0.6159018745779214 \n",
      "\t26 \t\t 0.5935392010067947 \n",
      "\t27 \t\t 0.5725801510832773 \n",
      "\t28 \t\t 0.5529056116767356 \n",
      "\t29 \t\t 0.5344091537886855 \n",
      "\t30 \t\t 0.5169953965637945 \n",
      "\t31 \t\t 0.500578620233852 \n",
      "\t32 \t\t 0.48508158450855543 \n",
      "\t33 \t\t 0.47043451741008674 \n",
      "\t34 \t\t 0.45657424622829623 \n",
      "\t35 \t\t 0.4434434475599106 \n",
      "\t36 \t\t 0.43098999759969675 \n",
      "\t37 \t\t 0.4191664072123456 \n",
      "\t38 \t\t 0.40792932901297096 \n",
      "\t39 \t\t 0.39723912586274657 \n",
      "\t40 \t\t 0.38705949195275247 \n",
      "\t41 \t\t 0.37735711908838304 \n",
      "\t42 \t\t 0.36810140196484264 \n",
      "\t43 \t\t 0.3592641771926265 \n",
      "\t44 \t\t 0.350819491631972 \n",
      "\t45 \t\t 0.342743396258451 \n",
      "\t46 \t\t 0.3350137623344864 \n",
      "\t47 \t\t 0.3276101171235675 \n",
      "\t48 \t\t 0.32051349677176016 \n",
      "\t49 \t\t 0.3137063143080665 \n",
      "\t50 \t\t 0.3071722409915558 \n",
      "\t51 \t\t 0.30089609946795703 \n",
      "\t52 \t\t 0.29486376739821496 \n",
      "\t53 \t\t 0.28906209039233327 \n",
      "\t54 \t\t 0.2834788032281575 \n",
      "\t55 \t\t 0.27810245846076354 \n",
      "\t56 \t\t 0.2729223616363691 \n",
      "\t57 \t\t 0.26792851241885973 \n",
      "\t58 \t\t 0.2631115510180435 \n",
      "\t59 \t\t 0.25846270937962557 \n",
      "\t60 \t\t 0.253973766658403 \n",
      "\t61 \t\t 0.24963700855000184 \n",
      "\t62 \t\t 0.2454451901034775 \n",
      "\t63 \t\t 0.2413915016784391 \n",
      "\t64 \t\t 0.23746953774658752 \n",
      "\t65 \t\t 0.23367326826949575 \n",
      "\t66 \t\t 0.22999701241268275 \n",
      "\t67 \t\t 0.22643541438086423 \n",
      "\t68 \t\t 0.22298342118135192 \n",
      "\t69 \t\t 0.2196362621421252 \n",
      "\t70 \t\t 0.21638943002843647 \n",
      "\t71 \t\t 0.2132386636172698 \n",
      "\t72 \t\t 0.21017993160274806 \n",
      "\t73 \t\t 0.20720941771785087 \n",
      "\t74 \t\t 0.20432350696875937 \n",
      "\t75 \t\t 0.20151877288799588 \n",
      "\t76 \t\t 0.19879196572127425 \n",
      "\t77 \t\t 0.19614000147092975 \n",
      "\t78 \t\t 0.19355995172577284 \n",
      "\t79 \t\t 0.191049034213711 \n",
      "\t80 \t\t 0.18860460401909826 \n",
      "\t81 \t\t 0.18622414541201737 \n",
      "\t82 \t\t 0.1839052642413106 \n",
      "\t83 \t\t 0.18164568084742408 \n",
      "\t84 \t\t 0.17944322345489122 \n",
      "\t85 \t\t 0.1772958220077824 \n",
      "\t86 \t\t 0.1752015024144951 \n",
      "\t87 \t\t 0.17315838117115884 \n",
      "\t88 \t\t 0.17116466033545974 \n",
      "\t89 \t\t 0.16921862282500535 \n",
      "\t90 \t\t 0.167318628016511 \n",
      "\t91 \t\t 0.1654631076239987 \n",
      "\t92 \t\t 0.1636505618359543 \n",
      "\t93 \t\t 0.1618795556929892 \n",
      "\t94 \t\t 0.16014871568902292 \n",
      "\t95 \t\t 0.15845672658034965 \n",
      "\t96 \t\t 0.15680232838813005 \n",
      "\t97 \t\t 0.1551843135809984 \n",
      "\t98 \t\t 0.15360152442552225 \n",
      "\t99 \t\t 0.1520528504930817 \n",
      "\t100 \t\t 0.15053722631275393 \n"
     ]
    }
   ],
   "source": [
    "rec.fit(iters=100, latent_features=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### investigate the user-Item matrix created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>article_id</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>12</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>18</th>\n",
       "      <th>...</th>\n",
       "      <th>1028</th>\n",
       "      <th>1030</th>\n",
       "      <th>1035</th>\n",
       "      <th>1038</th>\n",
       "      <th>1042</th>\n",
       "      <th>1043</th>\n",
       "      <th>1044</th>\n",
       "      <th>1047</th>\n",
       "      <th>1048</th>\n",
       "      <th>1050</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 437 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "article_id  0     2     4     8     9     12    14    15    16    18    ...   \\\n",
       "user_id                                                                 ...    \n",
       "1            NaN   NaN   NaN   NaN   NaN   NaN   1.0   NaN   NaN   NaN  ...    \n",
       "2            NaN   NaN   NaN   NaN   NaN   1.0   NaN   NaN   NaN   NaN  ...    \n",
       "3            NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "4            NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "5            NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...    \n",
       "\n",
       "article_id  1028  1030  1035  1038  1042  1043  1044  1047  1048  1050  \n",
       "user_id                                                                 \n",
       "1            NaN   NaN   NaN   NaN   1.0   NaN   NaN   1.0   NaN   NaN  \n",
       "2            NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3            NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4            NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "5            NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[5 rows x 437 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec.user_item_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get some Infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb of users: 4258\n",
      "Nb of items: 437\n",
      "The user_id with the highest avg rating given: 4258\n",
      "The article_id with the highest avg rating received: 1050\n",
      "The article name with the highest avg rating received: Jupyter Notebooks with Scala, Python, or R Kernels\n",
      "Shape of the U matrix: (4258, 10)\n",
      "Shape of the V(transpose) matrix: (10, 437)\n"
     ]
    }
   ],
   "source": [
    "def info():\n",
    "    user_item = rec.user_item_df\n",
    "    nb_user = rec.n_users\n",
    "    nb_items = rec.n_items\n",
    "    item_name = rec.item_name_colname\n",
    "    item_id = rec.item_id_colname\n",
    "    u_mat = rec.user_mat\n",
    "    i_mat = rec.item_mat\n",
    "    user_high_rate = list(dict(user_item.mean(axis=1).sort_values(ascending=False).head(1)).keys())[0]\n",
    "    movie_id_high_rate = list(dict(user_item.mean(axis=0).sort_values(ascending=False).head(1)).keys())[0]\n",
    "    movie_name_high_rate = tuple(df_content[df_content[item_id] == movie_id_high_rate][item_name])[0]\n",
    "    \n",
    "\n",
    "    print(f\"Nb of users: {nb_user}\")\n",
    "    print(f\"Nb of items: {nb_items}\")\n",
    "    print(f\"The user_id with the highest avg rating given: {user_high_rate}\")\n",
    "    print(f\"The article_id with the highest avg rating received: {movie_id_high_rate}\")\n",
    "    print(f\"The article name with the highest avg rating received: {movie_name_high_rate}\")\n",
    "    print(f\"Shape of the U matrix: {u_mat.shape}\")\n",
    "    print(f\"Shape of the V(transpose) matrix: {i_mat.shape}\")\n",
    "\n",
    "info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "##### To make recommendation: given an item id we want to find similar items to this item. Similarity are found by computing the dot product of items with its transpose, the more the result of an item-item pair is high, the more they have in common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_get_similar_items():\n",
    "    item_content = np.array(df_content.iloc[:,2:]) # subset of the df of items that contains only dummy variables that you have created\n",
    "    item_content_transpose = np.transpose(item_content)\n",
    "    dot_prod = item_content.dot(item_content_transpose)\n",
    "    return dot_prod\n",
    "\n",
    "dot_product_matrix = prep_get_similar_items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The same here for user similarity (CF user-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user_similarity = rec.user_item_df.reset_index().replace(np.nan, 0)\n",
    "def prep_get_similar_user():\n",
    "    user_content = np.array(df_user_similarity.iloc[:,1:])\n",
    "    user_content_transpose = np.transpose(user_content)\n",
    "    dot_prod = user_content.dot(user_content_transpose)\n",
    "    return dot_prod\n",
    "\n",
    "dot_product_matrix_user = prep_get_similar_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imagine that we have an article that we want to promote, but we want the top 10 users who may interested by this offer, the item id is 984."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These users may interested by this item:\n",
      "- 3845\n",
      "- 2215\n",
      "- 1937\n",
      "- 2282\n",
      "- 3710\n",
      "- 871\n",
      "- 3222\n",
      "- 4209\n",
      "- 1668\n",
      "- 2196\n"
     ]
    }
   ],
   "source": [
    "user_item = rec.user_item_df\n",
    "def may_interested_by(item_id, top_n=10):\n",
    "    pred = {}\n",
    "    # iterate over each users and predict the rate it will give to this movie\n",
    "    for user in user_item.index:\n",
    "        pred[user] = rec.predict_rating(user_id=user, item_id=item_id)\n",
    "\n",
    "    top_10_pairs = sorted(pred.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    top_10_user_ids = []\n",
    "\n",
    "    for i in top_10_pairs:\n",
    "        top_10_user_ids.append(i[0])\n",
    "\n",
    "    return top_10_user_ids\n",
    "\n",
    "print('These users may interested by this item:')\n",
    "for i in may_interested_by(984, 10):\n",
    "    print(f\"- {i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare a function to display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_recommendations(rec_ids, rec_names, message, rec_ids_users, rec_user_articles):\n",
    "    \n",
    "    if type(rec_ids) == type(None):\n",
    "        print(f\"{message}\")\n",
    "    \n",
    "    else:\n",
    "        dict_id_name = dict(zip(rec_ids, rec_names))\n",
    "        \n",
    "        if type(rec_ids_users) != type(None):\n",
    "            print('Matrix Factorisation SVD:')\n",
    "            print(f\"\\t{message}\")\n",
    "            \n",
    "            for key, val  in dict_id_name.items():\n",
    "                print(f\"\\t- ID items: {key}\")\n",
    "                print(f\"\\tName: {val}\\n\")\n",
    "\n",
    "            print('CF User Based:')\n",
    "            print('\\tUser that are similar to you also seen:\\n')\n",
    "            for i in rec_user_articles[:5]:\n",
    "                print(f\"\\t- {i}\")\n",
    "        else:\n",
    "            print(f\"\\t{message}\")\n",
    "            dict_id_name = dict(zip(rec_ids, rec_names))\n",
    "            for key, val  in dict_id_name.items():\n",
    "                print(f\"\\t- ID items: {key}\")\n",
    "                print(f\"\\tName: {val}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Existing user\n",
    "\n",
    "- Because it is an existing user, recommendations are made using FunkSVD (matrix factorisation), it will predict the rating it will give to all items and get back the items associate with the the top predicted rate. The dot_product_matrix will not be used but is requiered in case of you want to find a similar item to another instead of finding best item for a user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Factorisation SVD:\n",
      "\tGlad to see you again! recommended for you:\n",
      "\n",
      "\t- ID items: 961\n",
      "\tName: Run DSX Notebooks on Amazon EMR\n",
      "\n",
      "\t- ID items: 675\n",
      "\tName: Load Db2 Warehouse on Cloud data with Apache Spark in DSX\n",
      "\n",
      "\t- ID items: 443\n",
      "\tName: Webinar: April 11 - Thinking inside the box: you can do that inside a data frame?!\n",
      "\n",
      "\t- ID items: 395\n",
      "\tName: Don’t overlook simpler techniques and algorithms\n",
      "\n",
      "\t- ID items: 884\n",
      "\tName: Beyond Parallelize and Collect\n",
      "\n",
      "CF User Based:\n",
      "\tUser that are similar to you also seen:\n",
      "\n",
      "\t- 0 to life-changing app: new apache systemml api on spark shell\n",
      "\t- jupyter notebook tutorial\n",
      "\t- developing for the ibm streaming analytics service\n",
      "\t- brunel 2.0 preview\n",
      "\t- tensorflow quick tips\n"
     ]
    }
   ],
   "source": [
    "rec_ids, rec_names, message, rec_ids_users, rec_user_articles = rec.make_recommendations(_id=3,\n",
    "                                                                                         dot_prod=dot_product_matrix,\n",
    "                                                                                         dot_prod_user= dot_product_matrix_user,\n",
    "                                                                                         _id_type='user',\n",
    "                                                                                         rec_num=5)\n",
    "display_recommendations(rec_ids, rec_names, message, rec_ids_users, rec_user_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### New User\n",
    "\n",
    "- Because it is new user, recommendations are given using ranked based method, which simply return back the most popular items according to the ratings given by users, the number of ratings, the recency of the ratings. The dot_product_matrix will not be used but is requiered in case of you want to find a similar item to another instead of finding best item for a user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranked Based:\n",
      "\tHey, you are new here, this is for you:\n",
      "\n",
      "\t- ID items: 43\n",
      "\tName: Working interactively with RStudio and notebooks in DSX\n",
      "\n",
      "\t- ID items: 151\n",
      "\tName: Deep Learning With Tensorflow Course by Big Data University\n",
      "\n",
      "\t- ID items: 124\n",
      "\tName: Python Machine Learning: Scikit-Learn Tutorial\n",
      "\n",
      "\t- ID items: 390\n",
      "\tName: Jupyter Notebook Tutorial\n",
      "\n",
      "\t- ID items: 20\n",
      "\tName: Introducing IBM Watson Studio \n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec_ids, rec_names, message, rec_ids_users, rec_user_articles = rec.make_recommendations(_id=8000,\n",
    "                                                                                         dot_prod=dot_product_matrix,\n",
    "                                                                                         dot_prod_user= dot_product_matrix_user,\n",
    "                                                                                         _id_type='user',\n",
    "                                                                                         rec_num=5)\n",
    "\n",
    "print('Ranked Based:')\n",
    "display_recommendations(rec_ids, rec_names, message, rec_ids_users, rec_user_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "#### Existing items\n",
    "\n",
    "- Here we enter an item id and would like to find similar items using the dot_product_matrix computed earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CF Content Based:\n",
      "\tSimilar items for id:100, corresponding to Use data assets in a project using IBM Data Catalog:\n",
      "\n",
      "\t- ID items: 16\n",
      "\tName: Higher-order Logistic Regression for Large Datasets\n",
      "\n",
      "\t- ID items: 100\n",
      "\tName: Use data assets in a project using IBM Data Catalog\n",
      "\n",
      "\t- ID items: 349\n",
      "\tName: IBM Data Science Experience White paper - SparkR Transforming R into a tool for big data analytics\n",
      "\n",
      "\t- ID items: 417\n",
      "\tName: IBM Data Catalog Overview\n",
      "\n",
      "\t- ID items: 453\n",
      "\tName: Baby’s first IBM Graph app using Node.js – IBM Watson Data Lab\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec_ids, rec_names, message, rec_ids_users, rec_user_articles = rec.make_recommendations(_id=100,\n",
    "                                                                                         dot_prod=dot_product_matrix,\n",
    "                                                                                         dot_prod_user= dot_product_matrix_user,\n",
    "                                                                                         _id_type='item',\n",
    "                                                                                         rec_num=5, window=3) #change the window arg if you don't have the rec_num declared \n",
    "\n",
    "print('CF Content Based:')\n",
    "display_recommendations(rec_ids, rec_names, message, rec_ids_users, rec_user_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulate an error by passing a non existing item id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can't make recommendation for this item, please makesure the data was updated with this item.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec_ids, rec_names, message, rec_ids_users, rec_user_articles = rec.make_recommendations(_id=1087630,\n",
    "                                                                                         dot_prod=dot_product_matrix,\n",
    "                                                                                         dot_prod_user= dot_product_matrix_user,\n",
    "                                                                                         _id_type='item',\n",
    "                                                                                         rec_num=5, window=2)\n",
    "\n",
    "\n",
    "display_recommendations(rec_ids, rec_names, message, rec_ids_users, rec_user_articles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
