{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import recommender as r\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('user-item-interactions.csv')\n",
    "df_content = pd.read_csv('articles_community.csv')\n",
    "del df['Unnamed: 0']\n",
    "del df_content['Unnamed: 0']\n",
    "\n",
    "df = df.fillna('no_email')\n",
    "\n",
    "# make sure all articles from df are in df_content\n",
    "df = pd.merge(df, df_content[['article_id']], on='article_id', how='inner')\n",
    "\n",
    "pre_data = dict(df.groupby(['email', 'article_id'])['article_id'].count())\n",
    "\n",
    "list_email = []\n",
    "list_article_id = []\n",
    "list_nb_interactions = []\n",
    "\n",
    "for key, val in pre_data.items():\n",
    "    list_email.append(key[0])\n",
    "    list_article_id.append(key[1])\n",
    "    list_nb_interactions.append(val)\n",
    "    \n",
    "zipped_list = list(zip(list_email, list_article_id, list_nb_interactions))\n",
    "interaction_user = pd.DataFrame(zipped_list, columns=['email','article_id','nb_interactions'])\n",
    "\n",
    "df = pd.merge(df, interaction_user, on=['email', 'article_id'])\n",
    "\n",
    "df_content = df_content.drop(labels='doc_status', axis=1)\n",
    "df_content = df_content.drop_duplicates()\n",
    "\n",
    "df = df.replace('no_email', np.nan)\n",
    "\n",
    "def email_mapper():\n",
    "    coded_dict = dict()\n",
    "    cter = 1\n",
    "    email_encoded = []\n",
    "    \n",
    "    for val in df['email']:\n",
    "        if val not in coded_dict:\n",
    "            coded_dict[val] = cter\n",
    "            cter+=1\n",
    "        \n",
    "        email_encoded.append(coded_dict[val])\n",
    "    return email_encoded\n",
    "\n",
    "email_encoded = email_mapper()\n",
    "del df['email']\n",
    "df['user_id'] = email_encoded\n",
    "\n",
    "#dict_views = dict(df.article_id.value_counts())\n",
    "#df['popularity_article_nb_views'] = df.article_id.map(dict_views)\n",
    "\n",
    "\n",
    "dict_interactions_total = dict(df.groupby('user_id')['article_id'].count())\n",
    "df['nb_interactions_total'] = df.user_id.map(dict_interactions_total)\n",
    "\n",
    "df['importance_article'] = np.where(df.nb_interactions_total > 19,\n",
    "                                    df.nb_interactions/df.nb_interactions_total,\n",
    "                                    np.nan)\n",
    "\n",
    "# just for the module (later), I'll change the name doc_full_name to title\n",
    "df_content['title'] = df_content['doc_full_name']\n",
    "df_content = df_content.drop(labels='doc_full_name', axis=1)\n",
    "\n",
    "# just for the module (later), I'll a column called date, set to 0\n",
    "df['date'] = 0\n",
    "\n",
    "df.article_id = df.article_id.astype('int64')\n",
    "df_content.article_id = df_content.article_id.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>nb_interactions</th>\n",
       "      <th>user_id</th>\n",
       "      <th>nb_interactions_total</th>\n",
       "      <th>importance_article</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  \\\n",
       "0         593  upload files to ibm data science experience us...   \n",
       "1         593  upload files to ibm data science experience us...   \n",
       "2         593  upload files to ibm data science experience us...   \n",
       "3         593  upload files to ibm data science experience us...   \n",
       "4         593  upload files to ibm data science experience us...   \n",
       "\n",
       "   nb_interactions  user_id  nb_interactions_total  importance_article  date  \n",
       "0                1        1                     40               0.025     0  \n",
       "1                1        2                     11                 NaN     0  \n",
       "2                2        3                      3                 NaN     0  \n",
       "3                2        3                      3                 NaN     0  \n",
       "4                1        4                      1                 NaN     0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>Detect bad readings in real time using Python ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Detect Malfunctioning IoT Sensors with Streami...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...</td>\n",
       "      <td>See the forest, see the trees. Here lies the c...</td>\n",
       "      <td>1</td>\n",
       "      <td>Communicating data science: A guide to present...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...</td>\n",
       "      <td>Here’s this week’s news in Data Science and Bi...</td>\n",
       "      <td>2</td>\n",
       "      <td>This Week in Data Science (April 18, 2017)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...</td>\n",
       "      <td>Learn how distributed DBs solve the problem of...</td>\n",
       "      <td>3</td>\n",
       "      <td>DataLayer Conference: Boost the performance of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>This video demonstrates the power of IBM DataS...</td>\n",
       "      <td>4</td>\n",
       "      <td>Analyze NY Restaurant data using Spark in DSX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            doc_body  \\\n",
       "0  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "1  No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...   \n",
       "2  ☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...   \n",
       "3  DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...   \n",
       "4  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "\n",
       "                                     doc_description  article_id  \\\n",
       "0  Detect bad readings in real time using Python ...           0   \n",
       "1  See the forest, see the trees. Here lies the c...           1   \n",
       "2  Here’s this week’s news in Data Science and Bi...           2   \n",
       "3  Learn how distributed DBs solve the problem of...           3   \n",
       "4  This video demonstrates the power of IBM DataS...           4   \n",
       "\n",
       "                                               title  \n",
       "0  Detect Malfunctioning IoT Sensors with Streami...  \n",
       "1  Communicating data science: A guide to present...  \n",
       "2         This Week in Data Science (April 18, 2017)  \n",
       "3  DataLayer Conference: Boost the performance of...  \n",
       "4      Analyze NY Restaurant data using Spark in DSX  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_content.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Engineering the feature Using NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>insights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>Detect bad readings in real time using Python ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Detect Malfunctioning IoT Sensors with Streami...</td>\n",
       "      <td>detect,malfunctioning,iot,streaming,analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...</td>\n",
       "      <td>See the forest, see the trees. Here lies the c...</td>\n",
       "      <td>1</td>\n",
       "      <td>Communicating data science: A guide to present...</td>\n",
       "      <td>data,science,work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...</td>\n",
       "      <td>Here’s this week’s news in Data Science and Bi...</td>\n",
       "      <td>2</td>\n",
       "      <td>This Week in Data Science (April 18, 2017)</td>\n",
       "      <td>data,science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...</td>\n",
       "      <td>Learn how distributed DBs solve the problem of...</td>\n",
       "      <td>3</td>\n",
       "      <td>DataLayer Conference: Boost the performance of...</td>\n",
       "      <td>datalayer,performance,database</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>This video demonstrates the power of IBM DataS...</td>\n",
       "      <td>4</td>\n",
       "      <td>Analyze NY Restaurant data using Spark in DSX</td>\n",
       "      <td>analyze,ny,restaurant,spark,dsx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            doc_body  \\\n",
       "0  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "1  No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...   \n",
       "2  ☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...   \n",
       "3  DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...   \n",
       "4  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "\n",
       "                                     doc_description  article_id  \\\n",
       "0  Detect bad readings in real time using Python ...           0   \n",
       "1  See the forest, see the trees. Here lies the c...           1   \n",
       "2  Here’s this week’s news in Data Science and Bi...           2   \n",
       "3  Learn how distributed DBs solve the problem of...           3   \n",
       "4  This video demonstrates the power of IBM DataS...           4   \n",
       "\n",
       "                                               title  \\\n",
       "0  Detect Malfunctioning IoT Sensors with Streami...   \n",
       "1  Communicating data science: A guide to present...   \n",
       "2         This Week in Data Science (April 18, 2017)   \n",
       "3  DataLayer Conference: Boost the performance of...   \n",
       "4      Analyze NY Restaurant data using Spark in DSX   \n",
       "\n",
       "                                        insights  \n",
       "0  detect,malfunctioning,iot,streaming,analytics  \n",
       "1                              data,science,work  \n",
       "2                                   data,science  \n",
       "3                 datalayer,performance,database  \n",
       "4                analyze,ny,restaurant,spark,dsx  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nlp_task(data):\n",
    "    sent = data\n",
    "    doc=nlp(sent)\n",
    "    sub_toks = [tok for tok in doc if ((tok.dep_ == \"compound\") or (tok.dep_ == \"dobj\") or (tok.dep_ == \"pobj\")) ]\n",
    "    insight_words = [str(i).lower() for i in sub_toks]\n",
    "    insight_words = ','.join(insight_words)\n",
    "    return insight_words\n",
    "\n",
    "df_content['insights'] = df_content.title.apply(nlp_task)\n",
    "df_content.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create list of insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "insights_list = []\n",
    "\n",
    "for i in df_content.insights:\n",
    "    try:\n",
    "        insights_list.extend(i.split(','))\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "#normalize\n",
    "insights_list = [i.lower() for i in insights_list]\n",
    "\n",
    "#remove all non character from the list\n",
    "regex = re.compile('[^a-zA-Z]')\n",
    "insights_list = [regex.sub('non_charac', i) for i in insights_list]\n",
    "insights_list = set(insights_list)\n",
    "insights_list.remove('non_charac')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fill df_content with columns of insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_insights(val):\n",
    "    try:\n",
    "        if val.find(insight) > -1:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except AttributeError:\n",
    "        return 0\n",
    "    \n",
    "for insight in insights_list:\n",
    "    df_content[insight] = df_content['insights'].apply(split_insights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>insights</th>\n",
       "      <th>cloudflare</th>\n",
       "      <th></th>\n",
       "      <th>prem</th>\n",
       "      <th>ods</th>\n",
       "      <th>zapier</th>\n",
       "      <th>...</th>\n",
       "      <th>study</th>\n",
       "      <th>envoy</th>\n",
       "      <th>flight</th>\n",
       "      <th>impressive</th>\n",
       "      <th>containers</th>\n",
       "      <th>documents</th>\n",
       "      <th>leverage</th>\n",
       "      <th>amazing</th>\n",
       "      <th>engagement</th>\n",
       "      <th>entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>Detect bad readings in real time using Python ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Detect Malfunctioning IoT Sensors with Streami...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...</td>\n",
       "      <td>See the forest, see the trees. Here lies the c...</td>\n",
       "      <td>1</td>\n",
       "      <td>Communicating data science: A guide to present...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...</td>\n",
       "      <td>Here’s this week’s news in Data Science and Bi...</td>\n",
       "      <td>2</td>\n",
       "      <td>This Week in Data Science (April 18, 2017)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...</td>\n",
       "      <td>Learn how distributed DBs solve the problem of...</td>\n",
       "      <td>3</td>\n",
       "      <td>DataLayer Conference: Boost the performance of...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>This video demonstrates the power of IBM DataS...</td>\n",
       "      <td>4</td>\n",
       "      <td>Analyze NY Restaurant data using Spark in DSX</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1064 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            doc_body  \\\n",
       "0  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "1  No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...   \n",
       "2  ☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...   \n",
       "3  DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...   \n",
       "4  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "\n",
       "                                     doc_description  article_id  \\\n",
       "0  Detect bad readings in real time using Python ...           0   \n",
       "1  See the forest, see the trees. Here lies the c...           1   \n",
       "2  Here’s this week’s news in Data Science and Bi...           2   \n",
       "3  Learn how distributed DBs solve the problem of...           3   \n",
       "4  This video demonstrates the power of IBM DataS...           4   \n",
       "\n",
       "                                               title  insights  cloudflare     \\\n",
       "0  Detect Malfunctioning IoT Sensors with Streami...         0           0  1   \n",
       "1  Communicating data science: A guide to present...         0           0  1   \n",
       "2         This Week in Data Science (April 18, 2017)         0           0  1   \n",
       "3  DataLayer Conference: Boost the performance of...         0           0  1   \n",
       "4      Analyze NY Restaurant data using Spark in DSX         0           0  1   \n",
       "\n",
       "   prem  ods  zapier   ...    study  envoy  flight  impressive  containers  \\\n",
       "0     0    0       0   ...        0      0       0           0           0   \n",
       "1     0    0       0   ...        0      0       0           0           0   \n",
       "2     0    0       0   ...        0      0       0           0           0   \n",
       "3     0    0       0   ...        0      0       0           0           0   \n",
       "4     0    0       0   ...        0      0       0           0           0   \n",
       "\n",
       "   documents  leverage  amazing  engagement  entity  \n",
       "0          0         0        0           0       0  \n",
       "1          0         0        0           0       0  \n",
       "2          0         0        0           0       0  \n",
       "3          0         0        0           0       0  \n",
       "4          0         0        0           0       0  \n",
       "\n",
       "[5 rows x 1064 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_content.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove some columns\n",
    "df_content = df_content.drop(labels=['insights', 'doc_body', 'doc_description', ''], axis=1)\n",
    "df = df.drop(labels=['nb_interactions', 'nb_interactions_total'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = r.Recommender(df_items=df_content,\n",
    "                    df_reviews=df,\n",
    "                    item_name_colname='title',\n",
    "                    user_id_colname='user_id',\n",
    "                    item_id_colname='article_id',\n",
    "                    rating_col_name='importance_article',\n",
    "                    date_col_name='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create User-Item matrix...\n",
      "Train data with Funk Sigular Value Decomposition...\n",
      "Iterations \t\t Mean Squared Error \n",
      "\t1 \t\t 6.398577980221514 \n",
      "\t2 \t\t 6.05508220795138 \n",
      "\t3 \t\t 5.740668637572722 \n",
      "\t4 \t\t 5.4520068695821555 \n",
      "\t5 \t\t 5.186242355343206 \n",
      "\t6 \t\t 4.940915639852629 \n",
      "\t7 \t\t 4.713897355547736 \n",
      "\t8 \t\t 4.50333551861026 \n",
      "\t9 \t\t 4.307612512021063 \n",
      "\t10 \t\t 4.1253097535685574 \n"
     ]
    }
   ],
   "source": [
    "rec.fit(iters=10, latent_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare dot matrice for recommendations...\n",
      "Ok\n"
     ]
    }
   ],
   "source": [
    "print('prepare dot matrice for recommendations...')\n",
    "\n",
    "def prep_get_similar_items():\n",
    "    item_content = np.array(df_content.iloc[:,2:])\n",
    "    item_content_transpose = np.transpose(item_content)\n",
    "    dot_prod = item_content.dot(item_content_transpose)\n",
    "    return dot_prod\n",
    "\n",
    "dot_product_matrix = prep_get_similar_items()\n",
    "print('Ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_recommendations(rec_ids, rec_names, message):\n",
    "    dict_id_name = dict(zip(rec_ids, rec_names))\n",
    "\n",
    "    print(f\"{message}\")\n",
    "\n",
    "    for key, val  in dict_id_name.items():\n",
    "        print(f\"ID items: {key}\")\n",
    "        print(f\"Name: {val}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Existing user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_ids, rec_names, message = rec.make_recommendations(_id=1,\n",
    "                                                       dot_prod=dot_product_matrix,\n",
    "                                                       _id_type='user',\n",
    "                                                       rec_num=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glad to see you again! recommended for you:\n",
      "\n",
      "ID items: 36\n",
      "Name: Data visualization playbook: The right level of detail\n",
      "\n",
      "ID items: 195\n",
      "Name: Advancements in the Spark Community\n",
      "\n",
      "ID items: 399\n",
      "Name: Artificial Intelligence, Ethically Speaking – Inside Machine learning – Medium\n",
      "\n",
      "ID items: 58\n",
      "Name: Predicting The 2016 US Presidential Election\n",
      "\n",
      "ID items: 727\n",
      "Name: From Python Nested Lists to Multidimensional numpy Arrays\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_recommendations(rec_ids, rec_names, message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "New User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_ids, rec_names, message = rec.make_recommendations(_id=8000,\n",
    "                                                       dot_prod=dot_product_matrix,\n",
    "                                                       _id_type='user',\n",
    "                                                       rec_num=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey, you are new here, this is for you:\n",
      "\n",
      "ID items: 251\n",
      "Name: Data science expert interview: Dez Blanchfield, Craig Brown, David Mathison, Jennifer Shin and Mike Tamir part 2\n",
      "\n",
      "ID items: 1018\n",
      "Name: Clustering: A Guide for the Perplexed\n",
      "\n",
      "ID items: 977\n",
      "Name: Rapidly build Machine Learning flows with DSX\n",
      "\n",
      "ID items: 366\n",
      "Name: Apache Spark as the New Engine of Genomics\n",
      "\n",
      "ID items: 732\n",
      "Name: 7 types of job profiles that makes you a Data Scientist\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_recommendations(rec_ids, rec_names, message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "Existing items (find similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_ids, rec_names, message = rec.make_recommendations(_id=100,\n",
    "                                                       dot_prod=dot_product_matrix,\n",
    "                                                       _id_type='item',\n",
    "                                                       rec_num=5, window=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar items for id:100, corresponding to Use data assets in a project using IBM Data Catalog:\n",
      "\n",
      "ID items: 0\n",
      "Name: Detect Malfunctioning IoT Sensors with Streaming Analytics\n",
      "\n",
      "ID items: 5\n",
      "Name: Browsing PostgreSQL Data with Compose\n",
      "\n",
      "ID items: 6\n",
      "Name: Upgrading your PostgreSQL to 9.5\n",
      "\n",
      "ID items: 11\n",
      "Name: Warehousing GeoJSON documents\n",
      "\n",
      "ID items: 15\n",
      "Name: Apache Spark™ 2.0: Extend Structured Streaming for Spark ML\n",
      "\n"
     ]
    }
   ],
   "source": [
    "display_recommendations(rec_ids, rec_names, message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
