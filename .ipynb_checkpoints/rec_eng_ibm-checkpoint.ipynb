{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import recommender as r\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('user-item-interactions.csv')\n",
    "df_content = pd.read_csv('articles_community.csv')\n",
    "del df['Unnamed: 0']\n",
    "del df_content['Unnamed: 0']\n",
    "\n",
    "df = df.fillna('no_email')\n",
    "\n",
    "# make sure all articles from df are in df_content\n",
    "df = pd.merge(df, df_content[['article_id']], on='article_id', how='inner')\n",
    "\n",
    "pre_data = dict(df.groupby(['email', 'article_id'])['article_id'].count())\n",
    "\n",
    "list_email = []\n",
    "list_article_id = []\n",
    "list_nb_interactions = []\n",
    "\n",
    "for key, val in pre_data.items():\n",
    "    list_email.append(key[0])\n",
    "    list_article_id.append(key[1])\n",
    "    list_nb_interactions.append(val)\n",
    "    \n",
    "zipped_list = list(zip(list_email, list_article_id, list_nb_interactions))\n",
    "interaction_user = pd.DataFrame(zipped_list, columns=['email','article_id','nb_interactions'])\n",
    "\n",
    "df = pd.merge(df, interaction_user, on=['email', 'article_id'])\n",
    "\n",
    "df_content = df_content.drop(labels='doc_status', axis=1)\n",
    "df_content = df_content.drop_duplicates()\n",
    "\n",
    "df = df.replace('no_email', np.nan)\n",
    "\n",
    "def email_mapper():\n",
    "    coded_dict = dict()\n",
    "    cter = 1\n",
    "    email_encoded = []\n",
    "    \n",
    "    for val in df['email']:\n",
    "        if val not in coded_dict:\n",
    "            coded_dict[val] = cter\n",
    "            cter+=1\n",
    "        \n",
    "        email_encoded.append(coded_dict[val])\n",
    "    return email_encoded\n",
    "\n",
    "email_encoded = email_mapper()\n",
    "del df['email']\n",
    "df['user_id'] = email_encoded\n",
    "\n",
    "#dict_views = dict(df.article_id.value_counts())\n",
    "#df['popularity_article_nb_views'] = df.article_id.map(dict_views)\n",
    "\n",
    "\n",
    "dict_interactions_total = dict(df.groupby('user_id')['article_id'].count())\n",
    "df['nb_interactions_total'] = df.user_id.map(dict_interactions_total)\n",
    "\n",
    "df['importance_article'] = np.where(df.nb_interactions_total > 19,\n",
    "                                    df.nb_interactions/df.nb_interactions_total,\n",
    "                                    np.nan)\n",
    "\n",
    "# just for the module (later), I'll change the name doc_full_name to title\n",
    "df_content['title'] = df_content['doc_full_name']\n",
    "df_content = df_content.drop(labels='doc_full_name', axis=1)\n",
    "\n",
    "# just for the module (later), I'll a column called date, set to 0\n",
    "df['date'] = 0\n",
    "\n",
    "df.article_id = df.article_id.astype('int64')\n",
    "df_content.article_id = df_content.article_id.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>nb_interactions</th>\n",
       "      <th>user_id</th>\n",
       "      <th>nb_interactions_total</th>\n",
       "      <th>importance_article</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>593</td>\n",
       "      <td>upload files to ibm data science experience us...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  \\\n",
       "0         593  upload files to ibm data science experience us...   \n",
       "1         593  upload files to ibm data science experience us...   \n",
       "2         593  upload files to ibm data science experience us...   \n",
       "3         593  upload files to ibm data science experience us...   \n",
       "4         593  upload files to ibm data science experience us...   \n",
       "\n",
       "   nb_interactions  user_id  nb_interactions_total  importance_article  date  \n",
       "0                1        1                     40               0.025     0  \n",
       "1                1        2                     11                 NaN     0  \n",
       "2                2        3                      3                 NaN     0  \n",
       "3                2        3                      3                 NaN     0  \n",
       "4                1        4                      1                 NaN     0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>Detect bad readings in real time using Python ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Detect Malfunctioning IoT Sensors with Streami...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...</td>\n",
       "      <td>See the forest, see the trees. Here lies the c...</td>\n",
       "      <td>1</td>\n",
       "      <td>Communicating data science: A guide to present...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...</td>\n",
       "      <td>Here’s this week’s news in Data Science and Bi...</td>\n",
       "      <td>2</td>\n",
       "      <td>This Week in Data Science (April 18, 2017)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...</td>\n",
       "      <td>Learn how distributed DBs solve the problem of...</td>\n",
       "      <td>3</td>\n",
       "      <td>DataLayer Conference: Boost the performance of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>This video demonstrates the power of IBM DataS...</td>\n",
       "      <td>4</td>\n",
       "      <td>Analyze NY Restaurant data using Spark in DSX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            doc_body  \\\n",
       "0  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "1  No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...   \n",
       "2  ☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...   \n",
       "3  DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...   \n",
       "4  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "\n",
       "                                     doc_description  article_id  \\\n",
       "0  Detect bad readings in real time using Python ...           0   \n",
       "1  See the forest, see the trees. Here lies the c...           1   \n",
       "2  Here’s this week’s news in Data Science and Bi...           2   \n",
       "3  Learn how distributed DBs solve the problem of...           3   \n",
       "4  This video demonstrates the power of IBM DataS...           4   \n",
       "\n",
       "                                               title  \n",
       "0  Detect Malfunctioning IoT Sensors with Streami...  \n",
       "1  Communicating data science: A guide to present...  \n",
       "2         This Week in Data Science (April 18, 2017)  \n",
       "3  DataLayer Conference: Boost the performance of...  \n",
       "4      Analyze NY Restaurant data using Spark in DSX  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_content.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Engineering the feature Using NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>insights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>Detect bad readings in real time using Python ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Detect Malfunctioning IoT Sensors with Streami...</td>\n",
       "      <td>detect,malfunctioning,iot,streaming,analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...</td>\n",
       "      <td>See the forest, see the trees. Here lies the c...</td>\n",
       "      <td>1</td>\n",
       "      <td>Communicating data science: A guide to present...</td>\n",
       "      <td>data,science,work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...</td>\n",
       "      <td>Here’s this week’s news in Data Science and Bi...</td>\n",
       "      <td>2</td>\n",
       "      <td>This Week in Data Science (April 18, 2017)</td>\n",
       "      <td>data,science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...</td>\n",
       "      <td>Learn how distributed DBs solve the problem of...</td>\n",
       "      <td>3</td>\n",
       "      <td>DataLayer Conference: Boost the performance of...</td>\n",
       "      <td>datalayer,performance,database</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>This video demonstrates the power of IBM DataS...</td>\n",
       "      <td>4</td>\n",
       "      <td>Analyze NY Restaurant data using Spark in DSX</td>\n",
       "      <td>analyze,ny,restaurant,spark,dsx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            doc_body  \\\n",
       "0  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "1  No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...   \n",
       "2  ☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...   \n",
       "3  DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...   \n",
       "4  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "\n",
       "                                     doc_description  article_id  \\\n",
       "0  Detect bad readings in real time using Python ...           0   \n",
       "1  See the forest, see the trees. Here lies the c...           1   \n",
       "2  Here’s this week’s news in Data Science and Bi...           2   \n",
       "3  Learn how distributed DBs solve the problem of...           3   \n",
       "4  This video demonstrates the power of IBM DataS...           4   \n",
       "\n",
       "                                               title  \\\n",
       "0  Detect Malfunctioning IoT Sensors with Streami...   \n",
       "1  Communicating data science: A guide to present...   \n",
       "2         This Week in Data Science (April 18, 2017)   \n",
       "3  DataLayer Conference: Boost the performance of...   \n",
       "4      Analyze NY Restaurant data using Spark in DSX   \n",
       "\n",
       "                                        insights  \n",
       "0  detect,malfunctioning,iot,streaming,analytics  \n",
       "1                              data,science,work  \n",
       "2                                   data,science  \n",
       "3                 datalayer,performance,database  \n",
       "4                analyze,ny,restaurant,spark,dsx  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def nlp_task(data):\n",
    "    sent = data\n",
    "    doc=nlp(sent)\n",
    "    sub_toks = [tok for tok in doc if ((tok.dep_ == \"compound\") or (tok.dep_ == \"dobj\") or (tok.dep_ == \"pobj\")) ]\n",
    "    insight_words = [str(i).lower() for i in sub_toks]\n",
    "    insight_words = ','.join(insight_words)\n",
    "    return insight_words\n",
    "\n",
    "df_content['insights'] = df_content.title.apply(nlp_task)\n",
    "df_content.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create list of insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "insights_list = []\n",
    "\n",
    "for i in df_content.insights:\n",
    "    try:\n",
    "        insights_list.extend(i.split(','))\n",
    "    except AttributeError:\n",
    "        pass\n",
    "\n",
    "#normalize\n",
    "insights_list = [i.lower() for i in insights_list]\n",
    "\n",
    "#remove all non character from the list\n",
    "regex = re.compile('[^a-zA-Z]')\n",
    "insights_list = [regex.sub('non_charac', i) for i in insights_list]\n",
    "insights_list = set(insights_list)\n",
    "insights_list.remove('non_charac')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fill df_content with columns of insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_insights(val):\n",
    "    try:\n",
    "        if val.find(insight) > -1:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    except AttributeError:\n",
    "        return 0\n",
    "    \n",
    "for insight in insights_list:\n",
    "    df_content[insight] = df_content['insights'].apply(split_insights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_body</th>\n",
       "      <th>doc_description</th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>insights</th>\n",
       "      <th></th>\n",
       "      <th>translating</th>\n",
       "      <th>campaign</th>\n",
       "      <th>ops</th>\n",
       "      <th>brewery</th>\n",
       "      <th>...</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>apps</th>\n",
       "      <th>foundational</th>\n",
       "      <th>action</th>\n",
       "      <th>artificial</th>\n",
       "      <th>adversarial</th>\n",
       "      <th>summit</th>\n",
       "      <th>prem</th>\n",
       "      <th>serverless</th>\n",
       "      <th>datasets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>Detect bad readings in real time using Python ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Detect Malfunctioning IoT Sensors with Streami...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...</td>\n",
       "      <td>See the forest, see the trees. Here lies the c...</td>\n",
       "      <td>1</td>\n",
       "      <td>Communicating data science: A guide to present...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...</td>\n",
       "      <td>Here’s this week’s news in Data Science and Bi...</td>\n",
       "      <td>2</td>\n",
       "      <td>This Week in Data Science (April 18, 2017)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...</td>\n",
       "      <td>Learn how distributed DBs solve the problem of...</td>\n",
       "      <td>3</td>\n",
       "      <td>DataLayer Conference: Boost the performance of...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skip navigation Sign in SearchLoading...\\r\\n\\r...</td>\n",
       "      <td>This video demonstrates the power of IBM DataS...</td>\n",
       "      <td>4</td>\n",
       "      <td>Analyze NY Restaurant data using Spark in DSX</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1064 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            doc_body  \\\n",
       "0  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "1  No Free Hunch Navigation * kaggle.com\\r\\n\\r\\n ...   \n",
       "2  ☰ * Login\\r\\n * Sign Up\\r\\n\\r\\n * Learning Pat...   \n",
       "3  DATALAYER: HIGH THROUGHPUT, LOW LATENCY AT SCA...   \n",
       "4  Skip navigation Sign in SearchLoading...\\r\\n\\r...   \n",
       "\n",
       "                                     doc_description  article_id  \\\n",
       "0  Detect bad readings in real time using Python ...           0   \n",
       "1  See the forest, see the trees. Here lies the c...           1   \n",
       "2  Here’s this week’s news in Data Science and Bi...           2   \n",
       "3  Learn how distributed DBs solve the problem of...           3   \n",
       "4  This video demonstrates the power of IBM DataS...           4   \n",
       "\n",
       "                                               title  insights     \\\n",
       "0  Detect Malfunctioning IoT Sensors with Streami...         0  1   \n",
       "1  Communicating data science: A guide to present...         0  1   \n",
       "2         This Week in Data Science (April 18, 2017)         0  1   \n",
       "3  DataLayer Conference: Boost the performance of...         0  1   \n",
       "4      Analyze NY Restaurant data using Spark in DSX         0  1   \n",
       "\n",
       "   translating  campaign  ops  brewery    ...     hashtags  apps  \\\n",
       "0            0         0    0        0    ...            0     0   \n",
       "1            0         0    0        0    ...            0     0   \n",
       "2            0         0    0        0    ...            0     0   \n",
       "3            0         0    0        0    ...            0     0   \n",
       "4            0         0    0        0    ...            0     0   \n",
       "\n",
       "   foundational  action  artificial  adversarial  summit  prem  serverless  \\\n",
       "0             0       0           0            0       0     0           0   \n",
       "1             0       0           0            0       0     0           0   \n",
       "2             0       0           0            0       0     0           0   \n",
       "3             0       0           0            0       0     0           0   \n",
       "4             0       0           0            0       0     0           0   \n",
       "\n",
       "   datasets  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 1064 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_content.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove some columns\n",
    "df_content = df_content.drop(labels=['insights', 'doc_body', 'doc_description', ''], axis=1)\n",
    "df = df.drop(labels=['nb_interactions', 'nb_interactions_total'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = r.Recommender(df_items=df_content,\n",
    "                    df_reviews=df,\n",
    "                    item_name_colname='title',\n",
    "                    user_id_colname='user_id',\n",
    "                    item_id_colname='article_id',\n",
    "                    rating_col_name='importance_article',\n",
    "                    date_col_name='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create User-Item matrix...\n",
      "Train data with Funk Sigular Value Decomposition...\n",
      "Iterations \t\t Mean Squared Error \n",
      "\t1 \t\t 13.012184135500059 \n",
      "\t2 \t\t 12.057805437759072 \n",
      "\t3 \t\t 11.211637970456854 \n",
      "\t4 \t\t 10.457326576568285 \n",
      "\t5 \t\t 9.7815609964612 \n",
      "\t6 \t\t 9.173410199553405 \n",
      "\t7 \t\t 8.623822262571538 \n",
      "\t8 \t\t 8.125244001829591 \n",
      "\t9 \t\t 7.671328423152714 \n",
      "\t10 \t\t 7.256707381182806 \n",
      "\t11 \t\t 6.876813221918509 \n",
      "\t12 \t\t 6.527737614322864 \n",
      "\t13 \t\t 6.206118897140071 \n",
      "\t14 \t\t 5.90905149203967 \n",
      "\t15 \t\t 5.634012539623515 \n",
      "\t16 \t\t 5.378802086040513 \n",
      "\t17 \t\t 5.141494011225916 \n",
      "\t18 \t\t 4.920395532237928 \n",
      "\t19 \t\t 4.7140135976223725 \n",
      "\t20 \t\t 4.521026854132409 \n",
      "\t21 \t\t 4.340262146090047 \n",
      "\t22 \t\t 4.170674722255931 \n",
      "\t23 \t\t 4.0113314913171525 \n",
      "\t24 \t\t 3.8613967967642537 \n",
      "\t25 \t\t 3.720120283711936 \n",
      "\t26 \t\t 3.5868265105999066 \n",
      "\t27 \t\t 3.4609060225605086 \n",
      "\t28 \t\t 3.341807654236752 \n",
      "\t29 \t\t 3.229031870778695 \n",
      "\t30 \t\t 3.122124988785418 \n",
      "\t31 \t\t 3.02067414574675 \n",
      "\t32 \t\t 2.92430290835504 \n",
      "\t33 \t\t 2.832667427905891 \n",
      "\t34 \t\t 2.745453065665916 \n",
      "\t35 \t\t 2.6623714231785924 \n",
      "\t36 \t\t 2.583157722489336 \n",
      "\t37 \t\t 2.50756848959099 \n",
      "\t38 \t\t 2.4353795013285264 \n",
      "\t39 \t\t 2.3663839618074403 \n",
      "\t40 \t\t 2.300390879225275 \n",
      "\t41 \t\t 2.2372236181505247 \n",
      "\t42 \t\t 2.1767186057418813 \n",
      "\t43 \t\t 2.1187241733395497 \n",
      "\t44 \t\t 2.063099517357054 \n",
      "\t45 \t\t 2.0097137655303636 \n",
      "\t46 \t\t 1.9584451363983764 \n",
      "\t47 \t\t 1.9091801814459717 \n",
      "\t48 \t\t 1.8618131006779686 \n",
      "\t49 \t\t 1.8162451235425532 \n",
      "\t50 \t\t 1.772383948116231 \n",
      "\t51 \t\t 1.7301432323199701 \n",
      "\t52 \t\t 1.689442131681 \n",
      "\t53 \t\t 1.6502048787999863 \n",
      "\t54 \t\t 1.612360400246138 \n",
      "\t55 \t\t 1.5758419670925634 \n",
      "\t56 \t\t 1.5405868757328658 \n",
      "\t57 \t\t 1.5065361559945534 \n",
      "\t58 \t\t 1.47363430389384 \n",
      "\t59 \t\t 1.4418290366651212 \n",
      "\t60 \t\t 1.411071067952557 \n",
      "\t61 \t\t 1.3813139012753253 \n",
      "\t62 \t\t 1.3525136400759137 \n",
      "\t63 \t\t 1.3246288128357764 \n",
      "\t64 \t\t 1.2976202118976445 \n",
      "\t65 \t\t 1.2714507447714019 \n",
      "\t66 \t\t 1.246085296822318 \n",
      "\t67 \t\t 1.2214906043494622 \n",
      "\t68 \t\t 1.1976351371586493 \n",
      "\t69 \t\t 1.174488989820931 \n",
      "\t70 \t\t 1.1520237808845821 \n",
      "\t71 \t\t 1.130212559377866 \n",
      "\t72 \t\t 1.1090297180014905 \n",
      "\t73 \t\t 1.0884509124652935 \n",
      "\t74 \t\t 1.0684529864734786 \n",
      "\t75 \t\t 1.0490139019074884 \n",
      "\t76 \t\t 1.030112673795971 \n",
      "\t77 \t\t 1.0117293096975766 \n",
      "\t78 \t\t 0.9938447531552195 \n",
      "\t79 \t\t 0.9764408309098439 \n",
      "\t80 \t\t 0.9595002035887062 \n",
      "\t81 \t\t 0.9430063196073204 \n",
      "\t82 \t\t 0.9269433720461168 \n",
      "\t83 \t\t 0.9112962582829085 \n",
      "\t84 \t\t 0.8960505421801916 \n",
      "\t85 \t\t 0.8811924186427909 \n",
      "\t86 \t\t 0.8667086803763768 \n",
      "\t87 \t\t 0.8525866866907734 \n",
      "\t88 \t\t 0.8388143342046324 \n",
      "\t89 \t\t 0.8253800293191281 \n",
      "\t90 \t\t 0.8122726623387861 \n",
      "\t91 \t\t 0.7994815831269091 \n",
      "\t92 \t\t 0.7869965781917498 \n",
      "\t93 \t\t 0.7748078491073832 \n",
      "\t94 \t\t 0.7629059921805896 \n",
      "\t95 \t\t 0.7512819792815043 \n",
      "\t96 \t\t 0.7399271397620489 \n",
      "\t97 \t\t 0.7288331433916205 \n",
      "\t98 \t\t 0.7179919842446706 \n",
      "\t99 \t\t 0.7073959654795722 \n",
      "\t100 \t\t 0.6970376849523866 \n",
      "\t101 \t\t 0.6869100216132844 \n",
      "\t102 \t\t 0.6770061226369736 \n",
      "\t103 \t\t 0.6673193912418363 \n",
      "\t104 \t\t 0.6578434751557263 \n",
      "\t105 \t\t 0.6485722556892026 \n",
      "\t106 \t\t 0.63949983737957 \n",
      "\t107 \t\t 0.6306205381717778 \n",
      "\t108 \t\t 0.6219288801042424 \n",
      "\t109 \t\t 0.6134195804700314 \n",
      "\t110 \t\t 0.605087543425614 \n",
      "\t111 \t\t 0.5969278520212958 \n",
      "\t112 \t\t 0.588935760629124 \n",
      "\t113 \t\t 0.5811066877456079 \n",
      "\t114 \t\t 0.5734362091480094 \n",
      "\t115 \t\t 0.5659200513844116 \n",
      "\t116 \t\t 0.558554085578902 \n",
      "\t117 \t\t 0.5513343215344371 \n",
      "\t118 \t\t 0.5442569021170709 \n",
      "\t119 \t\t 0.5373180979061724 \n",
      "\t120 \t\t 0.5305143020962018 \n",
      "\t121 \t\t 0.523842025636587 \n",
      "\t122 \t\t 0.5172978925969091 \n",
      "\t123 \t\t 0.5108786357455031 \n",
      "\t124 \t\t 0.5045810923302307 \n",
      "\t125 \t\t 0.4984022000508302 \n",
      "\t126 \t\t 0.49233899321289715 \n",
      "\t127 \t\t 0.4863885990541683 \n",
      "\t128 \t\t 0.4805482342342148 \n",
      "\t129 \t\t 0.4748152014793049 \n",
      "\t130 \t\t 0.46918688637449946 \n",
      "\t131 \t\t 0.46366075429570514 \n",
      "\t132 \t\t 0.4582343474745692 \n",
      "\t133 \t\t 0.4529052821897559 \n",
      "\t134 \t\t 0.4476712460782945 \n",
      "\t135 \t\t 0.4425299955611859 \n",
      "\t136 \t\t 0.4374793533776383 \n",
      "\t137 \t\t 0.43251720622279066 \n",
      "\t138 \t\t 0.4276415024838556 \n",
      "\t139 \t\t 0.42285025007004834 \n",
      "\t140 \t\t 0.4181415143318425 \n",
      "\t141 \t\t 0.4135134160653322 \n",
      "\t142 \t\t 0.40896412959774586 \n",
      "\t143 \t\t 0.40449188095028743 \n",
      "\t144 \t\t 0.400094946074797 \n",
      "\t145 \t\t 0.3957716491607742 \n",
      "\t146 \t\t 0.3915203610095822 \n",
      "\t147 \t\t 0.38733949747278884 \n",
      "\t148 \t\t 0.38322751795172116 \n",
      "\t149 \t\t 0.37918292395550907 \n",
      "\t150 \t\t 0.3752042577150085 \n",
      "\t151 \t\t 0.37129010085011066 \n",
      "\t152 \t\t 0.367439073088097 \n",
      "\t153 \t\t 0.36364983103079507 \n",
      "\t154 \t\t 0.3599210669684214 \n",
      "\t155 \t\t 0.35625150773805336 \n",
      "\t156 \t\t 0.3526399136248704 \n",
      "\t157 \t\t 0.34908507730424654 \n",
      "\t158 \t\t 0.34558582282304207 \n",
      "\t159 \t\t 0.34214100461835983 \n",
      "\t160 \t\t 0.3387495065722405 \n",
      "\t161 \t\t 0.3354102411007549 \n",
      "\t162 \t\t 0.33212214827608794 \n",
      "\t163 \t\t 0.3288841949802163 \n",
      "\t164 \t\t 0.32569537408891125 \n",
      "\t165 \t\t 0.3225547036847983 \n",
      "\t166 \t\t 0.31946122629829504 \n",
      "\t167 \t\t 0.3164140081753055 \n",
      "\t168 \t\t 0.313412138570578 \n",
      "\t169 \t\t 0.31045472906570504 \n",
      "\t170 \t\t 0.3075409129107817 \n",
      "\t171 \t\t 0.30466984438877576 \n",
      "\t172 \t\t 0.3018406982017218 \n",
      "\t173 \t\t 0.29905266887787385 \n",
      "\t174 \t\t 0.29630497019899826 \n",
      "\t175 \t\t 0.293596834647032 \n",
      "\t176 \t\t 0.2909275128693452 \n",
      "\t177 \t\t 0.28829627316188744 \n",
      "\t178 \t\t 0.28570240096956645 \n",
      "\t179 \t\t 0.28314519840314417 \n",
      "\t180 \t\t 0.2806239837720846 \n",
      "\t181 \t\t 0.27813809113270793 \n",
      "\t182 \t\t 0.2756868698510957 \n",
      "\t183 \t\t 0.2732696841801944 \n",
      "\t184 \t\t 0.2708859128505806 \n",
      "\t185 \t\t 0.26853494867439337 \n",
      "\t186 \t\t 0.26621619816194114 \n",
      "\t187 \t\t 0.26392908115052205 \n",
      "\t188 \t\t 0.2616730304450094 \n",
      "\t189 \t\t 0.2594474914697782 \n",
      "\t190 \t\t 0.2572519219315617 \n",
      "\t191 \t\t 0.2550857914928454 \n",
      "\t192 \t\t 0.25294858145541915 \n",
      "\t193 \t\t 0.2508397844537309 \n",
      "\t194 \t\t 0.24875890415768034 \n",
      "\t195 \t\t 0.2467054549845479 \n",
      "\t196 \t\t 0.2446789618197019 \n",
      "\t197 \t\t 0.24267895974580508 \n",
      "\t198 \t\t 0.2407049937802128 \n",
      "\t199 \t\t 0.23875661862027736 \n",
      "\t200 \t\t 0.23683339839629644 \n"
     ]
    }
   ],
   "source": [
    "rec.fit(iters=200, latent_features=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### investigate the user-Item matrix created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>article_id</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>12</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>18</th>\n",
       "      <th>...</th>\n",
       "      <th>1028</th>\n",
       "      <th>1030</th>\n",
       "      <th>1035</th>\n",
       "      <th>1038</th>\n",
       "      <th>1042</th>\n",
       "      <th>1043</th>\n",
       "      <th>1044</th>\n",
       "      <th>1047</th>\n",
       "      <th>1048</th>\n",
       "      <th>1050</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 437 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "article_id  0     2     4     8     9     12     14    15    16    18    ...   \\\n",
       "user_id                                                                  ...    \n",
       "1            NaN   NaN   NaN   NaN   NaN   NaN  0.025   NaN   NaN   NaN  ...    \n",
       "2            NaN   NaN   NaN   NaN   NaN   NaN    NaN   NaN   NaN   NaN  ...    \n",
       "3            NaN   NaN   NaN   NaN   NaN   NaN    NaN   NaN   NaN   NaN  ...    \n",
       "4            NaN   NaN   NaN   NaN   NaN   NaN    NaN   NaN   NaN   NaN  ...    \n",
       "5            NaN   NaN   NaN   NaN   NaN   NaN    NaN   NaN   NaN   NaN  ...    \n",
       "\n",
       "article_id  1028  1030  1035  1038   1042  1043  1044   1047  1048  1050  \n",
       "user_id                                                                   \n",
       "1            NaN   NaN   NaN   NaN  0.025   NaN   NaN  0.025   NaN   NaN  \n",
       "2            NaN   NaN   NaN   NaN    NaN   NaN   NaN    NaN   NaN   NaN  \n",
       "3            NaN   NaN   NaN   NaN    NaN   NaN   NaN    NaN   NaN   NaN  \n",
       "4            NaN   NaN   NaN   NaN    NaN   NaN   NaN    NaN   NaN   NaN  \n",
       "5            NaN   NaN   NaN   NaN    NaN   NaN   NaN    NaN   NaN   NaN  \n",
       "\n",
       "[5 rows x 437 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec.user_item_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info():\n",
    "    user_item = rec.user_item_df\n",
    "    nb_user = rec.n_users\n",
    "    nb_items = rec.n_items\n",
    "    item_name = rec.item_name_colname\n",
    "    item_id = rec.item_id_colname\n",
    "    u_mat = rec.user_mat\n",
    "    i_mat = rec.item_mat\n",
    "    user_high_rate = list(dict(user_item.mean(axis=1).sort_values(ascending=False).head(1)).keys())[0]\n",
    "    movie_id_high_rate = list(dict(user_item.mean(axis=0).sort_values(ascending=False).head(1)).keys())[0]\n",
    "    movie_name_high_rate = tuple(df_content[df_content[item_id] == movie_id_high_rate][item_name])[0]\n",
    "    \n",
    "\n",
    "    print(f\"Nb of users: {nb_user}\")\n",
    "    print(f\"Nb of items: {nb_items}\")\n",
    "    print(f\"The user_id with the highest avg rating given: {user_high_rate}\")\n",
    "    print(f\"The article_id with the highest avg rating received: {movie_id_high_rate}\")\n",
    "    print(f\"The article name with the highest avg rating received: {movie_name_high_rate}\")\n",
    "    print(f\"Shape of the U matrix: {u_mat.shape}\")\n",
    "    print(f\"Shape of the V(transpose) matrix: {i_mat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb of users: 4258\n",
      "Nb of items: 437\n",
      "The user_id with the highest avg rating given: 954\n",
      "The article_id with the highest avg rating received: 366\n",
      "The article name with the highest avg rating received: Clustering: A Guide for the Perplexed\n",
      "Shape of the U matrix: (4258, 15)\n",
      "Shape of the V(transpose) matrix: (15, 437)\n"
     ]
    }
   ],
   "source": [
    "info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imagine that we have an article that we want to promote, but we want the top 10 users who may interested by this offer, the movie id is 984."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def may_interested_by(item_id, top_n=10):\n",
    "    pred = {}\n",
    "    # iterate over each users and predict the rate it will give to this movie\n",
    "    for user in user_item.index:\n",
    "        pred[user] = rec.predict_rating(user_id=user, item_id=item_id)\n",
    "\n",
    "    top_10_pairs = sorted(pred.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "    top_10_user_ids = []\n",
    "\n",
    "    for i in top_10_pairs:\n",
    "        top_10_user_ids.append(i[0])\n",
    "\n",
    "    return top_10_user_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3358, 3889, 1405, 3402, 4193, 4192, 1149, 2896, 750, 2974]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "may_interested_by(984, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To make recommendation: given an item id we want to find similar items to this item. Similarity are found by computing the dot product of items with its transpose, the more the result of an item-item pair is high, the more they have in common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare dot matrice for recommendations...\n",
      "Ok\n"
     ]
    }
   ],
   "source": [
    "print('prepare dot matrice for recommendations...')\n",
    "\n",
    "def prep_get_similar_items():\n",
    "    item_content = np.array(df_content.iloc[:,2:])\n",
    "    item_content_transpose = np.transpose(item_content)\n",
    "    dot_prod = item_content.dot(item_content_transpose)\n",
    "    return dot_prod\n",
    "\n",
    "dot_product_matrix = prep_get_similar_items()\n",
    "print('Ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9, 1, 1, ..., 1, 0, 1],\n",
       "       [1, 4, 3, ..., 1, 0, 1],\n",
       "       [1, 3, 3, ..., 1, 0, 1],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 5, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 2, 0],\n",
       "       [1, 1, 1, ..., 1, 0, 2]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_product_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### As we can see, maximum values are in the diagonal because the most similar item to an item is itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_recommendations(rec_ids, rec_names, message):\n",
    "    \n",
    "    if type(rec_ids) == type(None):\n",
    "        print(f\"{message}\")\n",
    "    \n",
    "    else:\n",
    "        dict_id_name = dict(zip(rec_ids, rec_names))\n",
    "        \n",
    "        print(f\"{message}\")\n",
    "        \n",
    "        for key, val  in dict_id_name.items():\n",
    "            print(f\"ID items: {key}\")\n",
    "            print(f\"Name: {val}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### Existing user\n",
    "\n",
    "- Because it is an existing user, recommendations are made using FunkSVD (matrix factorisation), it will predict the rating it will give to all items and get back the items associate with the the top predicted rate. The dot_product_matrix will not be used but is requiered in case of you want to find a similar item to another instead of finding best item for a user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glad to see you again! recommended for you:\n",
      "\n",
      "ID items: 984\n",
      "Name: Building a business that combines human experts and data science\n",
      "\n",
      "ID items: 662\n",
      "Name: Build Deep Learning Architectures With Neural Network Modeler\n",
      "\n",
      "ID items: 763\n",
      "Name: Load data into RStudio for analysis in DSX\n",
      "\n",
      "ID items: 973\n",
      "Name: Recent trends in recommender systems\n",
      "\n",
      "ID items: 586\n",
      "Name: The Data Processing Inequality\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec_ids, rec_names, message = rec.make_recommendations(_id=3358,\n",
    "                                                       dot_prod=dot_product_matrix,\n",
    "                                                       _id_type='user',\n",
    "                                                       rec_num=5)\n",
    "\n",
    "display_recommendations(rec_ids, rec_names, message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "#### New User\n",
    "\n",
    "- Because it is new user, recommendations are given using ranked based method, which simply return back the most popular items according to the ratings given by users, the number of ratings, the recency of the ratings. The dot_product_matrix will not be used but is requiered in case of you want to find a similar item to another instead of finding best item for a user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey, you are new here, this is for you:\n",
      "\n",
      "ID items: 251\n",
      "Name: Data science expert interview: Dez Blanchfield, Craig Brown, David Mathison, Jennifer Shin and Mike Tamir part 2\n",
      "\n",
      "ID items: 1018\n",
      "Name: Clustering: A Guide for the Perplexed\n",
      "\n",
      "ID items: 977\n",
      "Name: Rapidly build Machine Learning flows with DSX\n",
      "\n",
      "ID items: 366\n",
      "Name: Apache Spark as the New Engine of Genomics\n",
      "\n",
      "ID items: 732\n",
      "Name: 7 types of job profiles that makes you a Data Scientist\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec_ids, rec_names, message = rec.make_recommendations(_id=8000,\n",
    "                                                       dot_prod=dot_product_matrix,\n",
    "                                                       _id_type='user',\n",
    "                                                       rec_num=5)\n",
    "\n",
    "display_recommendations(rec_ids, rec_names, message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "#### Existing items\n",
    "\n",
    "- Here we enter an item id and would like to find similar items using the dot_product_matrix computed earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar items for id:100, corresponding to Use data assets in a project using IBM Data Catalog:\n",
      "\n",
      "ID items: 5\n",
      "Name: Browsing PostgreSQL Data with Compose\n",
      "\n",
      "ID items: 16\n",
      "Name: Higher-order Logistic Regression for Large Datasets\n",
      "\n",
      "ID items: 30\n",
      "Name: How open API economy accelerates the growth of big data and analytics\n",
      "\n",
      "ID items: 43\n",
      "Name: Deep Learning With Tensorflow Course by Big Data University\n",
      "\n",
      "ID items: 49\n",
      "Name: GeoFile: Using OpenStreetMap Data in Compose PostgreSQL - Part II\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec_ids, rec_names, message = rec.make_recommendations(_id=100,\n",
    "                                                       dot_prod=dot_product_matrix,\n",
    "                                                       _id_type='item',\n",
    "                                                       rec_num=5, window=1)\n",
    "\n",
    "display_recommendations(rec_ids, rec_names, message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulate an error by passing a non existing item id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can't make recommendation for this item, please makesure the data was updated with this item.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rec_ids, rec_names, message = rec.make_recommendations(_id=187600,\n",
    "                                                       dot_prod=dot_product_matrix,\n",
    "                                                       _id_type='item',\n",
    "                                                       rec_num=5, window=1)\n",
    "\n",
    "display_recommendations(rec_ids, rec_names, message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
